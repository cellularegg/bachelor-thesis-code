{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shared_logic import *\n",
    "\n",
    "random_seed = 1\n",
    "np.random.seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Width of the LaTeX document\n",
    "plt.style.use('seaborn-colorblind')\n",
    "# https://jwalton.info/Embed-Publication-Matplotlib-Latex/\n",
    "tex_fonts = {\n",
    "    # Use LaTeX to write all text\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    # Use 11pt font in plots, to match 11pt font in document\n",
    "    \"axes.labelsize\": 11,\n",
    "    \"font.size\": 11\n",
    "}\n",
    "plt.rcParams.update(tex_fonts)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def calculate_precision(tp, fp):\n",
    "    if tp + fp == 0:\n",
    "        return 0\n",
    "    return tp / (tp + fp)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def calculate_recall(tp, fn):\n",
    "    if tp + fn == 0:\n",
    "        return 0\n",
    "    return tp / (tp + fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 1.38 s, total: 1min 41s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "% % time\n",
    "stations_df = pd.read_csv('./data/stations.csv')\n",
    "stations_dict = stations_df.groupby(['common_id']).first().to_dict('index')\n",
    "common_id = '36022-ie'\n",
    "\n",
    "tex_plots_path = f'../bachelor-thesis/plots/pdfs/{common_id}/'\n",
    "tex_table_path = f'../bachelor-thesis/tables/{common_id}/'\n",
    "if not os.path.exists(tex_plots_path):\n",
    "    os.makedirs(tex_plots_path)\n",
    "if not os.path.exists(tex_table_path):\n",
    "    os.makedirs(tex_table_path)\n",
    "\n",
    "prediction_summary_df = pd.read_parquet(\n",
    "    './data/predictions/predictions_summary.parquet')\n",
    "preprocessed_prediction_summary_df = pd.read_parquet(\n",
    "    './data/predictions/predictions_preprocessed_summary.parquet')\n",
    "prediction_summary_df['recall'] = prediction_summary_df.apply(lambda row: calculate_recall(row['tp'], row['fn']),\n",
    "                                                              axis=1)\n",
    "prediction_summary_df['precision'] = prediction_summary_df.apply(lambda row: calculate_precision(row['tp'], row['fp']),\n",
    "                                                                 axis=1)\n",
    "preprocessed_prediction_summary_df['recall'] = preprocessed_prediction_summary_df.apply(\n",
    "    lambda row: calculate_recall(row['tp'], row['fn']), axis=1)\n",
    "preprocessed_prediction_summary_df['precision'] = preprocessed_prediction_summary_df.apply(\n",
    "    lambda row: calculate_precision(row['tp'], row['fp']), axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500000 entries, 0 to 1499999\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   common_id      1500000 non-null  object \n",
      " 1   window_size    1470000 non-null  float64\n",
      " 2   center_window  1500000 non-null  bool   \n",
      " 3   model_type     1500000 non-null  object \n",
      " 4   normalized     1500000 non-null  bool   \n",
      " 5   threshold      1500000 non-null  float64\n",
      " 6   f1_score       1500000 non-null  float64\n",
      " 7   tn             1500000 non-null  int64  \n",
      " 8   fp             1500000 non-null  int64  \n",
      " 9   fn             1500000 non-null  int64  \n",
      " 10  tp             1500000 non-null  int64  \n",
      " 11  recall         1500000 non-null  float64\n",
      " 12  precision      1500000 non-null  float64\n",
      "dtypes: bool(2), float64(5), int64(4), object(2)\n",
      "memory usage: 128.7+ MB\n"
     ]
    }
   ],
   "source": [
    "prediction_summary_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500000 entries, 0 to 1499999\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   common_id      1500000 non-null  object \n",
      " 1   window_size    1470000 non-null  float64\n",
      " 2   center_window  1500000 non-null  bool   \n",
      " 3   model_type     1500000 non-null  object \n",
      " 4   normalized     1500000 non-null  bool   \n",
      " 5   threshold      1500000 non-null  float64\n",
      " 6   f1_score       1500000 non-null  float64\n",
      " 7   tn             1500000 non-null  int64  \n",
      " 8   fp             1500000 non-null  int64  \n",
      " 9   fn             1500000 non-null  int64  \n",
      " 10  tp             1500000 non-null  int64  \n",
      " 11  recall         1500000 non-null  float64\n",
      " 12  precision      1500000 non-null  float64\n",
      "dtypes: bool(2), float64(5), int64(4), object(2)\n",
      "memory usage: 128.7+ MB\n"
     ]
    }
   ],
   "source": [
    "preprocessed_prediction_summary_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "        common_id   model_type\n0         2386-ch          mad\n1         2386-ch  mad-z-score\n2         2386-ch         mean\n3         2386-ch       median\n4         2386-ch      z-score\n5   2720050000-de          mad\n6   2720050000-de  mad-z-score\n7   2720050000-de         mean\n8   2720050000-de       median\n9   2720050000-de      z-score\n10       36022-ie          mad\n11       36022-ie  mad-z-score\n12       36022-ie         mean\n13       36022-ie       median\n14       36022-ie      z-score\n15       39003-ie          mad\n16       39003-ie  mad-z-score\n17       39003-ie         mean\n18       39003-ie       median\n19       39003-ie      z-score\n20    42960105-de          mad\n21    42960105-de  mad-z-score\n22    42960105-de         mean\n23    42960105-de       median\n24    42960105-de      z-score",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>common_id</th>\n      <th>model_type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2386-ch</td>\n      <td>mad</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2386-ch</td>\n      <td>mad-z-score</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2386-ch</td>\n      <td>mean</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2386-ch</td>\n      <td>median</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2386-ch</td>\n      <td>z-score</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2720050000-de</td>\n      <td>mad</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2720050000-de</td>\n      <td>mad-z-score</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2720050000-de</td>\n      <td>mean</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2720050000-de</td>\n      <td>median</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2720050000-de</td>\n      <td>z-score</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>36022-ie</td>\n      <td>mad</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>36022-ie</td>\n      <td>mad-z-score</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>36022-ie</td>\n      <td>mean</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>36022-ie</td>\n      <td>median</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>36022-ie</td>\n      <td>z-score</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>39003-ie</td>\n      <td>mad</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>39003-ie</td>\n      <td>mad-z-score</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>39003-ie</td>\n      <td>mean</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>39003-ie</td>\n      <td>median</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>39003-ie</td>\n      <td>z-score</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>42960105-de</td>\n      <td>mad</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>42960105-de</td>\n      <td>mad-z-score</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>42960105-de</td>\n      <td>mean</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>42960105-de</td>\n      <td>median</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>42960105-de</td>\n      <td>z-score</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_summary_df.groupby(['common_id', 'model_type']).any().reset_index()[['common_id', 'model_type']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# get unique combination of common id and model type\n",
    "# create a dictionary of dataframes for faster filtering\n",
    "prediction_summaries_dict = {}\n",
    "for idx, row in prediction_summary_df.groupby(['common_id', 'model_type']).any().reset_index()[\n",
    "    ['common_id', 'model_type']].iterrows():\n",
    "    prediction_summaries_dict[f'{row[\"common_id\"]}'] = {\n",
    "        'regular': prediction_summary_df.loc[prediction_summary_df['common_id'] == row['common_id']].copy(),\n",
    "        'preprocessed': preprocessed_prediction_summary_df.loc[\n",
    "            preprocessed_prediction_summary_df['common_id'] == row['common_id']].copy()\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_274729/491403784.py:12: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n"
     ]
    },
    {
     "data": {
      "text/plain": "        common_id  window_size  center_window   model_type  normalized  \\\n426620   36022-ie          5.0           True       median       False   \n426622   36022-ie          5.0           True       median       False   \n426621   36022-ie          5.0           True       median       False   \n1092308  36022-ie         24.0           True  mad-z-score        True   \n342308   36022-ie         24.0           True  mad-z-score       False   \n1053008  36022-ie         22.0           True  mad-z-score        True   \n303008   36022-ie         22.0           True  mad-z-score       False   \n1192510  36022-ie         26.0           True  mad-z-score        True   \n442510   36022-ie         26.0           True  mad-z-score       False   \n1076400  36022-ie          9.0           True       median        True   \n1111200  36022-ie          7.0           True       median        True   \n1150500  36022-ie          8.0           True       median        True   \n423903   36022-ie         24.0           True      z-score       False   \n1166104  36022-ie         32.0           True      z-score        True   \n416104   36022-ie         32.0           True      z-score       False   \n1087203  36022-ie         23.0           True      z-score        True   \n1095904  36022-ie         27.0           True      z-score        True   \n345904   36022-ie         27.0           True      z-score       False   \n435648   36022-ie          9.0           True         mean       False   \n411354   36022-ie         10.0           True         mean       False   \n411355   36022-ie         10.0           True         mean       False   \n1163701  36022-ie         11.0           True         mean        True   \n1185601  36022-ie          9.0           True         mean        True   \n1161301  36022-ie         10.0           True         mean        True   \n1172103  36022-ie         24.0           True          mad        True   \n1077603  36022-ie         26.0           True          mad        True   \n1157103  36022-ie         28.0           True          mad        True   \n408199   36022-ie         22.0           True          mad       False   \n408200   36022-ie         22.0           True          mad       False   \n408201   36022-ie         22.0           True          mad       False   \n\n         threshold  f1_score     tn   fp   fn   tp    recall  precision  \n426620    7.622074  0.812550  26451   93  140  505  0.782946   0.844482  \n426622    8.284281  0.812348  26458   86  145  500  0.775194   0.853242  \n426621    7.953177  0.811688  26457   87  145  500  0.775194   0.851789  \n1092308   3.648829  0.789205  26359  185  104  541  0.838760   0.745179  \n342308    3.648829  0.789205  26359  185  104  541  0.838760   0.745179  \n1053008   3.648829  0.787572  26350  194  100  545  0.844961   0.737483  \n303008    3.648829  0.787572  26350  194  100  545  0.844961   0.737483  \n1192510   4.311037  0.786415  26385  159  124  521  0.807752   0.766176  \n442510    4.311037  0.786415  26385  159  124  521  0.807752   0.766176  \n1076400   1.000000  0.759430  26449   95  192  453  0.702326   0.826642  \n1111200   1.000000  0.750670  26490   54  225  420  0.651163   0.886076  \n1150500   1.000000  0.749358  26458   86  207  438  0.679070   0.835878  \n423903    1.993311  0.626321  26474   70  319  326  0.505426   0.823232  \n1166104   2.324415  0.622718  26510   34  338  307  0.475969   0.900293  \n416104    2.324415  0.621457  26508   36  338  307  0.475969   0.895044  \n1087203   1.993311  0.621359  26479   65  325  320  0.496124   0.831169  \n1095904   2.324415  0.620833  26527   17  347  298  0.462016   0.946032  \n345904    2.324415  0.620833  26527   17  347  298  0.462016   0.946032  \n435648   16.892977  0.619647  26367  177  276  369  0.572093   0.675824  \n411354   18.879599  0.619173  26404  140  293  352  0.545736   0.715447  \n411355   19.210702  0.618538  26414  130  298  347  0.537984   0.727463  \n1163701   1.331104  0.611993  26402  142  298  347  0.537984   0.709611  \n1185601   1.331104  0.611418  26435  109  313  332  0.514729   0.752834  \n1161301   1.331104  0.610659  26420  124  307  338  0.524031   0.731602  \n1172103   1.993311  0.404255  25989  555  341  304  0.471318   0.353900  \n1077603   1.993311  0.404000  25992  552  342  303  0.469767   0.354386  \n1157103   1.993311  0.403183  25985  559  341  304  0.471318   0.352260  \n408199   66.889632  0.401679  26047  497  358  287  0.444961   0.366071  \n408200   67.220736  0.401126  26053  491  360  285  0.441860   0.367268  \n408201   67.551839  0.400856  26068  476  364  281  0.435659   0.371202  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>common_id</th>\n      <th>window_size</th>\n      <th>center_window</th>\n      <th>model_type</th>\n      <th>normalized</th>\n      <th>threshold</th>\n      <th>f1_score</th>\n      <th>tn</th>\n      <th>fp</th>\n      <th>fn</th>\n      <th>tp</th>\n      <th>recall</th>\n      <th>precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>426620</th>\n      <td>36022-ie</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>7.622074</td>\n      <td>0.812550</td>\n      <td>26451</td>\n      <td>93</td>\n      <td>140</td>\n      <td>505</td>\n      <td>0.782946</td>\n      <td>0.844482</td>\n    </tr>\n    <tr>\n      <th>426622</th>\n      <td>36022-ie</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>8.284281</td>\n      <td>0.812348</td>\n      <td>26458</td>\n      <td>86</td>\n      <td>145</td>\n      <td>500</td>\n      <td>0.775194</td>\n      <td>0.853242</td>\n    </tr>\n    <tr>\n      <th>426621</th>\n      <td>36022-ie</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>7.953177</td>\n      <td>0.811688</td>\n      <td>26457</td>\n      <td>87</td>\n      <td>145</td>\n      <td>500</td>\n      <td>0.775194</td>\n      <td>0.851789</td>\n    </tr>\n    <tr>\n      <th>1092308</th>\n      <td>36022-ie</td>\n      <td>24.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>3.648829</td>\n      <td>0.789205</td>\n      <td>26359</td>\n      <td>185</td>\n      <td>104</td>\n      <td>541</td>\n      <td>0.838760</td>\n      <td>0.745179</td>\n    </tr>\n    <tr>\n      <th>342308</th>\n      <td>36022-ie</td>\n      <td>24.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.789205</td>\n      <td>26359</td>\n      <td>185</td>\n      <td>104</td>\n      <td>541</td>\n      <td>0.838760</td>\n      <td>0.745179</td>\n    </tr>\n    <tr>\n      <th>1053008</th>\n      <td>36022-ie</td>\n      <td>22.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>3.648829</td>\n      <td>0.787572</td>\n      <td>26350</td>\n      <td>194</td>\n      <td>100</td>\n      <td>545</td>\n      <td>0.844961</td>\n      <td>0.737483</td>\n    </tr>\n    <tr>\n      <th>303008</th>\n      <td>36022-ie</td>\n      <td>22.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.787572</td>\n      <td>26350</td>\n      <td>194</td>\n      <td>100</td>\n      <td>545</td>\n      <td>0.844961</td>\n      <td>0.737483</td>\n    </tr>\n    <tr>\n      <th>1192510</th>\n      <td>36022-ie</td>\n      <td>26.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>4.311037</td>\n      <td>0.786415</td>\n      <td>26385</td>\n      <td>159</td>\n      <td>124</td>\n      <td>521</td>\n      <td>0.807752</td>\n      <td>0.766176</td>\n    </tr>\n    <tr>\n      <th>442510</th>\n      <td>36022-ie</td>\n      <td>26.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>4.311037</td>\n      <td>0.786415</td>\n      <td>26385</td>\n      <td>159</td>\n      <td>124</td>\n      <td>521</td>\n      <td>0.807752</td>\n      <td>0.766176</td>\n    </tr>\n    <tr>\n      <th>1076400</th>\n      <td>36022-ie</td>\n      <td>9.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.759430</td>\n      <td>26449</td>\n      <td>95</td>\n      <td>192</td>\n      <td>453</td>\n      <td>0.702326</td>\n      <td>0.826642</td>\n    </tr>\n    <tr>\n      <th>1111200</th>\n      <td>36022-ie</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.750670</td>\n      <td>26490</td>\n      <td>54</td>\n      <td>225</td>\n      <td>420</td>\n      <td>0.651163</td>\n      <td>0.886076</td>\n    </tr>\n    <tr>\n      <th>1150500</th>\n      <td>36022-ie</td>\n      <td>8.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.749358</td>\n      <td>26458</td>\n      <td>86</td>\n      <td>207</td>\n      <td>438</td>\n      <td>0.679070</td>\n      <td>0.835878</td>\n    </tr>\n    <tr>\n      <th>423903</th>\n      <td>36022-ie</td>\n      <td>24.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>1.993311</td>\n      <td>0.626321</td>\n      <td>26474</td>\n      <td>70</td>\n      <td>319</td>\n      <td>326</td>\n      <td>0.505426</td>\n      <td>0.823232</td>\n    </tr>\n    <tr>\n      <th>1166104</th>\n      <td>36022-ie</td>\n      <td>32.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>2.324415</td>\n      <td>0.622718</td>\n      <td>26510</td>\n      <td>34</td>\n      <td>338</td>\n      <td>307</td>\n      <td>0.475969</td>\n      <td>0.900293</td>\n    </tr>\n    <tr>\n      <th>416104</th>\n      <td>36022-ie</td>\n      <td>32.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>2.324415</td>\n      <td>0.621457</td>\n      <td>26508</td>\n      <td>36</td>\n      <td>338</td>\n      <td>307</td>\n      <td>0.475969</td>\n      <td>0.895044</td>\n    </tr>\n    <tr>\n      <th>1087203</th>\n      <td>36022-ie</td>\n      <td>23.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.621359</td>\n      <td>26479</td>\n      <td>65</td>\n      <td>325</td>\n      <td>320</td>\n      <td>0.496124</td>\n      <td>0.831169</td>\n    </tr>\n    <tr>\n      <th>1095904</th>\n      <td>36022-ie</td>\n      <td>27.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>2.324415</td>\n      <td>0.620833</td>\n      <td>26527</td>\n      <td>17</td>\n      <td>347</td>\n      <td>298</td>\n      <td>0.462016</td>\n      <td>0.946032</td>\n    </tr>\n    <tr>\n      <th>345904</th>\n      <td>36022-ie</td>\n      <td>27.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>2.324415</td>\n      <td>0.620833</td>\n      <td>26527</td>\n      <td>17</td>\n      <td>347</td>\n      <td>298</td>\n      <td>0.462016</td>\n      <td>0.946032</td>\n    </tr>\n    <tr>\n      <th>435648</th>\n      <td>36022-ie</td>\n      <td>9.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>16.892977</td>\n      <td>0.619647</td>\n      <td>26367</td>\n      <td>177</td>\n      <td>276</td>\n      <td>369</td>\n      <td>0.572093</td>\n      <td>0.675824</td>\n    </tr>\n    <tr>\n      <th>411354</th>\n      <td>36022-ie</td>\n      <td>10.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>18.879599</td>\n      <td>0.619173</td>\n      <td>26404</td>\n      <td>140</td>\n      <td>293</td>\n      <td>352</td>\n      <td>0.545736</td>\n      <td>0.715447</td>\n    </tr>\n    <tr>\n      <th>411355</th>\n      <td>36022-ie</td>\n      <td>10.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>19.210702</td>\n      <td>0.618538</td>\n      <td>26414</td>\n      <td>130</td>\n      <td>298</td>\n      <td>347</td>\n      <td>0.537984</td>\n      <td>0.727463</td>\n    </tr>\n    <tr>\n      <th>1163701</th>\n      <td>36022-ie</td>\n      <td>11.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.331104</td>\n      <td>0.611993</td>\n      <td>26402</td>\n      <td>142</td>\n      <td>298</td>\n      <td>347</td>\n      <td>0.537984</td>\n      <td>0.709611</td>\n    </tr>\n    <tr>\n      <th>1185601</th>\n      <td>36022-ie</td>\n      <td>9.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.331104</td>\n      <td>0.611418</td>\n      <td>26435</td>\n      <td>109</td>\n      <td>313</td>\n      <td>332</td>\n      <td>0.514729</td>\n      <td>0.752834</td>\n    </tr>\n    <tr>\n      <th>1161301</th>\n      <td>36022-ie</td>\n      <td>10.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.331104</td>\n      <td>0.610659</td>\n      <td>26420</td>\n      <td>124</td>\n      <td>307</td>\n      <td>338</td>\n      <td>0.524031</td>\n      <td>0.731602</td>\n    </tr>\n    <tr>\n      <th>1172103</th>\n      <td>36022-ie</td>\n      <td>24.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.404255</td>\n      <td>25989</td>\n      <td>555</td>\n      <td>341</td>\n      <td>304</td>\n      <td>0.471318</td>\n      <td>0.353900</td>\n    </tr>\n    <tr>\n      <th>1077603</th>\n      <td>36022-ie</td>\n      <td>26.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.404000</td>\n      <td>25992</td>\n      <td>552</td>\n      <td>342</td>\n      <td>303</td>\n      <td>0.469767</td>\n      <td>0.354386</td>\n    </tr>\n    <tr>\n      <th>1157103</th>\n      <td>36022-ie</td>\n      <td>28.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.403183</td>\n      <td>25985</td>\n      <td>559</td>\n      <td>341</td>\n      <td>304</td>\n      <td>0.471318</td>\n      <td>0.352260</td>\n    </tr>\n    <tr>\n      <th>408199</th>\n      <td>36022-ie</td>\n      <td>22.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>66.889632</td>\n      <td>0.401679</td>\n      <td>26047</td>\n      <td>497</td>\n      <td>358</td>\n      <td>287</td>\n      <td>0.444961</td>\n      <td>0.366071</td>\n    </tr>\n    <tr>\n      <th>408200</th>\n      <td>36022-ie</td>\n      <td>22.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>67.220736</td>\n      <td>0.401126</td>\n      <td>26053</td>\n      <td>491</td>\n      <td>360</td>\n      <td>285</td>\n      <td>0.441860</td>\n      <td>0.367268</td>\n    </tr>\n    <tr>\n      <th>408201</th>\n      <td>36022-ie</td>\n      <td>22.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>67.551839</td>\n      <td>0.400856</td>\n      <td>26068</td>\n      <td>476</td>\n      <td>364</td>\n      <td>281</td>\n      <td>0.435659</td>\n      <td>0.371202</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_id = '36022-ie'\n",
    "tex_table_path = f'../bachelor-thesis/tables/{common_id}/'\n",
    "model_types = prediction_summaries_dict[common_id]['regular']['model_type'].unique()\n",
    "combined_df_lst = []\n",
    "for model_type in model_types:\n",
    "    tmp_df = prediction_summaries_dict[common_id]['regular']\n",
    "    norm_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (tmp_df['normalized'])]\n",
    "    combined_df_lst.append(norm_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "    reg_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (~tmp_df['normalized'])]\n",
    "    combined_df_lst.append(reg_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "combined_df = pd.concat(combined_df_lst).sort_values(by=['f1_score', 'model_type'], ascending=False)\n",
    "combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(\n",
    "    f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n",
    "    label=f'table:{common_id}-top-predictions-summary', index=False,\n",
    "    caption=f'Top predictions summary of {stations_dict[common_id][\"water_name\"]} - {stations_dict[common_id][\"station_name\"]}')\n",
    "combined_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "        common_id  window_size  center_window   model_type  normalized  \\\n426620   36022-ie          5.0           True       median       False   \n426622   36022-ie          5.0           True       median       False   \n426621   36022-ie          5.0           True       median       False   \n1092308  36022-ie         24.0           True  mad-z-score        True   \n342308   36022-ie         24.0           True  mad-z-score       False   \n1053008  36022-ie         22.0           True  mad-z-score        True   \n303008   36022-ie         22.0           True  mad-z-score       False   \n1192510  36022-ie         26.0           True  mad-z-score        True   \n442510   36022-ie         26.0           True  mad-z-score       False   \n1076400  36022-ie          9.0           True       median        True   \n1111200  36022-ie          7.0           True       median        True   \n1150500  36022-ie          8.0           True       median        True   \n1173903  36022-ie         24.0           True      z-score        True   \n423903   36022-ie         24.0           True      z-score       False   \n1166104  36022-ie         32.0           True      z-score        True   \n416104   36022-ie         32.0           True      z-score       False   \n1095904  36022-ie         27.0           True      z-score        True   \n345904   36022-ie         27.0           True      z-score       False   \n411355   36022-ie         10.0           True         mean       False   \n411354   36022-ie         10.0           True         mean       False   \n435648   36022-ie          9.0           True         mean       False   \n1161301  36022-ie         10.0           True         mean        True   \n1185601  36022-ie          9.0           True         mean        True   \n1163701  36022-ie         11.0           True         mean        True   \n408199   36022-ie         22.0           True          mad       False   \n408201   36022-ie         22.0           True          mad       False   \n408200   36022-ie         22.0           True          mad       False   \n1172103  36022-ie         24.0           True          mad        True   \n1158003  36022-ie         22.0           True          mad        True   \n1077603  36022-ie         26.0           True          mad        True   \n\n         threshold  f1_score     tn   fp   fn   tp    recall  precision  \n426620    7.622074  0.801025  26451   93  140  469  0.770115   0.834520  \n426622    8.284281  0.800690  26458   86  145  464  0.761905   0.843636  \n426621    7.953177  0.800000  26457   87  145  464  0.761905   0.842105  \n1092308   3.648829  0.778802  26358  186  102  507  0.832512   0.731602  \n342308    3.648829  0.778802  26358  186  102  507  0.832512   0.731602  \n1053008   3.648829  0.777186  26349  195   98  511  0.839080   0.723796  \n303008    3.648829  0.777186  26349  195   98  511  0.839080   0.723796  \n1192510   4.311037  0.776096  26385  159  122  487  0.799672   0.753870  \n442510    4.311037  0.776096  26385  159  122  487  0.799672   0.753870  \n1076400   1.000000  0.752212  26448   96  184  425  0.697865   0.815739  \n1111200   1.000000  0.744318  26490   54  216  393  0.645320   0.879195  \n1150500   1.000000  0.741410  26457   87  199  410  0.673235   0.824950  \n1173903   1.993311  0.646123  26472   72  284  325  0.533662   0.818640  \n423903    1.993311  0.646123  26472   72  284  325  0.533662   0.818640  \n1166104   2.324415  0.645636  26509   35  302  307  0.504105   0.897661  \n416104    2.324415  0.644281  26507   37  302  307  0.504105   0.892442  \n1095904   2.324415  0.643554  26527   17  312  297  0.487685   0.945860  \n345904    2.324415  0.642857  26526   18  312  297  0.487685   0.942857  \n411355   19.210702  0.613508  26414  130  282  327  0.536946   0.715536  \n411354   18.879599  0.611677  26404  140  279  330  0.541872   0.702128  \n435648   16.892977  0.611160  26369  175  264  345  0.566502   0.663462  \n1161301   1.331104  0.610586  26418  126  286  323  0.530378   0.719376  \n1185601   1.331104  0.609284  26434  110  294  315  0.517241   0.741176  \n1163701   1.331104  0.608133  26400  144  280  329  0.540230   0.695560  \n408199   66.889632  0.409483  26046  498  324  285  0.467980   0.363985  \n408201   67.551839  0.409091  26068  476  330  279  0.458128   0.369536  \n408200   67.220736  0.408960  26052  492  326  283  0.464696   0.365161  \n1172103   1.993311  0.394791  25982  562  321  288  0.472906   0.338824  \n1158003   1.993311  0.394001  25975  569  320  289  0.474548   0.336830  \n1077603   1.993311  0.393151  25980  564  322  287  0.471264   0.337250  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>common_id</th>\n      <th>window_size</th>\n      <th>center_window</th>\n      <th>model_type</th>\n      <th>normalized</th>\n      <th>threshold</th>\n      <th>f1_score</th>\n      <th>tn</th>\n      <th>fp</th>\n      <th>fn</th>\n      <th>tp</th>\n      <th>recall</th>\n      <th>precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>426620</th>\n      <td>36022-ie</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>7.622074</td>\n      <td>0.801025</td>\n      <td>26451</td>\n      <td>93</td>\n      <td>140</td>\n      <td>469</td>\n      <td>0.770115</td>\n      <td>0.834520</td>\n    </tr>\n    <tr>\n      <th>426622</th>\n      <td>36022-ie</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>8.284281</td>\n      <td>0.800690</td>\n      <td>26458</td>\n      <td>86</td>\n      <td>145</td>\n      <td>464</td>\n      <td>0.761905</td>\n      <td>0.843636</td>\n    </tr>\n    <tr>\n      <th>426621</th>\n      <td>36022-ie</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>7.953177</td>\n      <td>0.800000</td>\n      <td>26457</td>\n      <td>87</td>\n      <td>145</td>\n      <td>464</td>\n      <td>0.761905</td>\n      <td>0.842105</td>\n    </tr>\n    <tr>\n      <th>1092308</th>\n      <td>36022-ie</td>\n      <td>24.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>3.648829</td>\n      <td>0.778802</td>\n      <td>26358</td>\n      <td>186</td>\n      <td>102</td>\n      <td>507</td>\n      <td>0.832512</td>\n      <td>0.731602</td>\n    </tr>\n    <tr>\n      <th>342308</th>\n      <td>36022-ie</td>\n      <td>24.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.778802</td>\n      <td>26358</td>\n      <td>186</td>\n      <td>102</td>\n      <td>507</td>\n      <td>0.832512</td>\n      <td>0.731602</td>\n    </tr>\n    <tr>\n      <th>1053008</th>\n      <td>36022-ie</td>\n      <td>22.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>3.648829</td>\n      <td>0.777186</td>\n      <td>26349</td>\n      <td>195</td>\n      <td>98</td>\n      <td>511</td>\n      <td>0.839080</td>\n      <td>0.723796</td>\n    </tr>\n    <tr>\n      <th>303008</th>\n      <td>36022-ie</td>\n      <td>22.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.777186</td>\n      <td>26349</td>\n      <td>195</td>\n      <td>98</td>\n      <td>511</td>\n      <td>0.839080</td>\n      <td>0.723796</td>\n    </tr>\n    <tr>\n      <th>1192510</th>\n      <td>36022-ie</td>\n      <td>26.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>4.311037</td>\n      <td>0.776096</td>\n      <td>26385</td>\n      <td>159</td>\n      <td>122</td>\n      <td>487</td>\n      <td>0.799672</td>\n      <td>0.753870</td>\n    </tr>\n    <tr>\n      <th>442510</th>\n      <td>36022-ie</td>\n      <td>26.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>4.311037</td>\n      <td>0.776096</td>\n      <td>26385</td>\n      <td>159</td>\n      <td>122</td>\n      <td>487</td>\n      <td>0.799672</td>\n      <td>0.753870</td>\n    </tr>\n    <tr>\n      <th>1076400</th>\n      <td>36022-ie</td>\n      <td>9.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.752212</td>\n      <td>26448</td>\n      <td>96</td>\n      <td>184</td>\n      <td>425</td>\n      <td>0.697865</td>\n      <td>0.815739</td>\n    </tr>\n    <tr>\n      <th>1111200</th>\n      <td>36022-ie</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.744318</td>\n      <td>26490</td>\n      <td>54</td>\n      <td>216</td>\n      <td>393</td>\n      <td>0.645320</td>\n      <td>0.879195</td>\n    </tr>\n    <tr>\n      <th>1150500</th>\n      <td>36022-ie</td>\n      <td>8.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.741410</td>\n      <td>26457</td>\n      <td>87</td>\n      <td>199</td>\n      <td>410</td>\n      <td>0.673235</td>\n      <td>0.824950</td>\n    </tr>\n    <tr>\n      <th>1173903</th>\n      <td>36022-ie</td>\n      <td>24.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.646123</td>\n      <td>26472</td>\n      <td>72</td>\n      <td>284</td>\n      <td>325</td>\n      <td>0.533662</td>\n      <td>0.818640</td>\n    </tr>\n    <tr>\n      <th>423903</th>\n      <td>36022-ie</td>\n      <td>24.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>1.993311</td>\n      <td>0.646123</td>\n      <td>26472</td>\n      <td>72</td>\n      <td>284</td>\n      <td>325</td>\n      <td>0.533662</td>\n      <td>0.818640</td>\n    </tr>\n    <tr>\n      <th>1166104</th>\n      <td>36022-ie</td>\n      <td>32.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>2.324415</td>\n      <td>0.645636</td>\n      <td>26509</td>\n      <td>35</td>\n      <td>302</td>\n      <td>307</td>\n      <td>0.504105</td>\n      <td>0.897661</td>\n    </tr>\n    <tr>\n      <th>416104</th>\n      <td>36022-ie</td>\n      <td>32.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>2.324415</td>\n      <td>0.644281</td>\n      <td>26507</td>\n      <td>37</td>\n      <td>302</td>\n      <td>307</td>\n      <td>0.504105</td>\n      <td>0.892442</td>\n    </tr>\n    <tr>\n      <th>1095904</th>\n      <td>36022-ie</td>\n      <td>27.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>2.324415</td>\n      <td>0.643554</td>\n      <td>26527</td>\n      <td>17</td>\n      <td>312</td>\n      <td>297</td>\n      <td>0.487685</td>\n      <td>0.945860</td>\n    </tr>\n    <tr>\n      <th>345904</th>\n      <td>36022-ie</td>\n      <td>27.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>2.324415</td>\n      <td>0.642857</td>\n      <td>26526</td>\n      <td>18</td>\n      <td>312</td>\n      <td>297</td>\n      <td>0.487685</td>\n      <td>0.942857</td>\n    </tr>\n    <tr>\n      <th>411355</th>\n      <td>36022-ie</td>\n      <td>10.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>19.210702</td>\n      <td>0.613508</td>\n      <td>26414</td>\n      <td>130</td>\n      <td>282</td>\n      <td>327</td>\n      <td>0.536946</td>\n      <td>0.715536</td>\n    </tr>\n    <tr>\n      <th>411354</th>\n      <td>36022-ie</td>\n      <td>10.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>18.879599</td>\n      <td>0.611677</td>\n      <td>26404</td>\n      <td>140</td>\n      <td>279</td>\n      <td>330</td>\n      <td>0.541872</td>\n      <td>0.702128</td>\n    </tr>\n    <tr>\n      <th>435648</th>\n      <td>36022-ie</td>\n      <td>9.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>16.892977</td>\n      <td>0.611160</td>\n      <td>26369</td>\n      <td>175</td>\n      <td>264</td>\n      <td>345</td>\n      <td>0.566502</td>\n      <td>0.663462</td>\n    </tr>\n    <tr>\n      <th>1161301</th>\n      <td>36022-ie</td>\n      <td>10.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.331104</td>\n      <td>0.610586</td>\n      <td>26418</td>\n      <td>126</td>\n      <td>286</td>\n      <td>323</td>\n      <td>0.530378</td>\n      <td>0.719376</td>\n    </tr>\n    <tr>\n      <th>1185601</th>\n      <td>36022-ie</td>\n      <td>9.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.331104</td>\n      <td>0.609284</td>\n      <td>26434</td>\n      <td>110</td>\n      <td>294</td>\n      <td>315</td>\n      <td>0.517241</td>\n      <td>0.741176</td>\n    </tr>\n    <tr>\n      <th>1163701</th>\n      <td>36022-ie</td>\n      <td>11.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.331104</td>\n      <td>0.608133</td>\n      <td>26400</td>\n      <td>144</td>\n      <td>280</td>\n      <td>329</td>\n      <td>0.540230</td>\n      <td>0.695560</td>\n    </tr>\n    <tr>\n      <th>408199</th>\n      <td>36022-ie</td>\n      <td>22.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>66.889632</td>\n      <td>0.409483</td>\n      <td>26046</td>\n      <td>498</td>\n      <td>324</td>\n      <td>285</td>\n      <td>0.467980</td>\n      <td>0.363985</td>\n    </tr>\n    <tr>\n      <th>408201</th>\n      <td>36022-ie</td>\n      <td>22.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>67.551839</td>\n      <td>0.409091</td>\n      <td>26068</td>\n      <td>476</td>\n      <td>330</td>\n      <td>279</td>\n      <td>0.458128</td>\n      <td>0.369536</td>\n    </tr>\n    <tr>\n      <th>408200</th>\n      <td>36022-ie</td>\n      <td>22.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>67.220736</td>\n      <td>0.408960</td>\n      <td>26052</td>\n      <td>492</td>\n      <td>326</td>\n      <td>283</td>\n      <td>0.464696</td>\n      <td>0.365161</td>\n    </tr>\n    <tr>\n      <th>1172103</th>\n      <td>36022-ie</td>\n      <td>24.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.394791</td>\n      <td>25982</td>\n      <td>562</td>\n      <td>321</td>\n      <td>288</td>\n      <td>0.472906</td>\n      <td>0.338824</td>\n    </tr>\n    <tr>\n      <th>1158003</th>\n      <td>36022-ie</td>\n      <td>22.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.394001</td>\n      <td>25975</td>\n      <td>569</td>\n      <td>320</td>\n      <td>289</td>\n      <td>0.474548</td>\n      <td>0.336830</td>\n    </tr>\n    <tr>\n      <th>1077603</th>\n      <td>36022-ie</td>\n      <td>26.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.393151</td>\n      <td>25980</td>\n      <td>564</td>\n      <td>322</td>\n      <td>287</td>\n      <td>0.471264</td>\n      <td>0.337250</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_id = '36022-ie'\n",
    "tex_table_path = f'../bachelor-thesis/tables/{common_id}/'\n",
    "model_types = prediction_summaries_dict[common_id]['preprocessed']['model_type'].unique()\n",
    "combined_df_lst = []\n",
    "for model_type in model_types:\n",
    "    tmp_df = prediction_summaries_dict[common_id]['preprocessed']\n",
    "    norm_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (tmp_df['normalized'])]\n",
    "    combined_df_lst.append(norm_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "    reg_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (~tmp_df['normalized'])]\n",
    "    combined_df_lst.append(reg_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "combined_df = pd.concat(combined_df_lst).sort_values(by=['f1_score', 'model_type'], ascending=False)\n",
    "# combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(\n",
    "#     f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n",
    "#     label=f'table:{common_id}-top-predictions-summary', index=False,\n",
    "#     caption=f'Top predictions summary of {stations_dict[common_id][\"water_name\"]} - {stations_dict[common_id][\"station_name\"]}')\n",
    "combined_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_274729/3983772253.py:12: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n"
     ]
    },
    {
     "data": {
      "text/plain": "       common_id  window_size  center_window   model_type  normalized  \\\n9315     2386-ch          3.0           True       median       False   \n9314     2386-ch          3.0           True       median       False   \n9317     2386-ch          3.0           True       median       False   \n4811     2386-ch          3.0           True         mean       False   \n4812     2386-ch          3.0           True         mean       False   \n4813     2386-ch          3.0           True         mean       False   \n800109   2386-ch         50.0           True      z-score        True   \n50109    2386-ch         50.0           True      z-score       False   \n769208   2386-ch         49.0           True      z-score        True   \n19208    2386-ch         49.0           True      z-score       False   \n80108    2386-ch         48.0           True      z-score       False   \n800108   2386-ch         50.0           True      z-score        True   \n751800   2386-ch         47.0           True       median        True   \n814533   2386-ch         42.0          False       median        True   \n814524   2386-ch         42.0          False       median        True   \n861670   2386-ch         49.0          False         mean        True   \n798625   2386-ch         34.0           True         mean        True   \n798618   2386-ch         34.0           True         mean        True   \n888783   2386-ch          NaN           True  mad-z-score        True   \n803091   2386-ch          NaN          False  mad-z-score        True   \n803093   2386-ch          NaN          False  mad-z-score        True   \n138783   2386-ch          NaN           True  mad-z-score       False   \n53091    2386-ch          NaN          False  mad-z-score       False   \n53093    2386-ch          NaN          False  mad-z-score       False   \n755400   2386-ch          7.0           True          mad        True   \n825603   2386-ch         11.0           True          mad        True   \n825372   2386-ch         34.0          False          mad        True   \n5400     2386-ch          7.0           True          mad       False   \n82212    2386-ch         27.0           True          mad       False   \n82214    2386-ch         27.0           True          mad       False   \n\n        threshold  f1_score     tn     fp   fn   tp    recall  precision  \n9315     5.966555  0.657895  50423     44   34   75  0.688073   0.630252  \n9314     5.635452  0.649351  50420     47   34   75  0.688073   0.614754  \n9317     6.628763  0.639175  50444     23   47   62  0.568807   0.729412  \n4811     4.642140  0.447917  50278    189   23   86  0.788991   0.312727  \n4812     4.973244  0.443804  50306    161   32   77  0.706422   0.323529  \n4813     5.304348  0.429907  50324    143   40   69  0.633028   0.325472  \n800109   3.979933  0.327273  50438     29   82   27  0.247706   0.482143  \n50109    3.979933  0.327273  50438     29   82   27  0.247706   0.482143  \n769208   3.648829  0.306931  50405     62   78   31  0.284404   0.333333  \n19208    3.648829  0.306931  50405     62   78   31  0.284404   0.333333  \n80108    3.648829  0.305419  50404     63   78   31  0.284404   0.329787  \n800108   3.648829  0.303922  50403     64   78   31  0.284404   0.326316  \n751800   1.000000  0.120690  50467      0  102    7  0.064220   1.000000  \n814533  11.926421  0.120690  50467      0  102    7  0.064220   1.000000  \n814524   8.946488  0.120690  50467      0  102    7  0.064220   1.000000  \n861670  24.177258  0.120690  50467      0  102    7  0.064220   1.000000  \n798625   9.277592  0.120690  50467      0  102    7  0.064220   1.000000  \n798618   6.959866  0.120690  50467      0  102    7  0.064220   1.000000  \n888783  61.591973  0.120690  50467      0  102    7  0.064220   1.000000  \n803091  97.351171  0.120690  50467      0  102    7  0.064220   1.000000  \n803093  98.013378  0.120690  50467      0  102    7  0.064220   1.000000  \n138783  61.591973  0.120690  50467      0  102    7  0.064220   1.000000  \n53091   97.351171  0.120690  50467      0  102    7  0.064220   1.000000  \n53093   98.013378  0.120690  50467      0  102    7  0.064220   1.000000  \n755400   1.000000  0.120690  50467      0  102    7  0.064220   1.000000  \n825603   1.993311  0.120690  50467      0  102    7  0.064220   1.000000  \n825372  24.839465  0.120690  50467      0  102    7  0.064220   1.000000  \n5400     1.000000  0.004301      0  50467    0  109  1.000000   0.002155  \n82212    4.973244  0.004301      0  50467    0  109  1.000000   0.002155  \n82214    5.635452  0.004301      0  50467    0  109  1.000000   0.002155  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>common_id</th>\n      <th>window_size</th>\n      <th>center_window</th>\n      <th>model_type</th>\n      <th>normalized</th>\n      <th>threshold</th>\n      <th>f1_score</th>\n      <th>tn</th>\n      <th>fp</th>\n      <th>fn</th>\n      <th>tp</th>\n      <th>recall</th>\n      <th>precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9315</th>\n      <td>2386-ch</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>5.966555</td>\n      <td>0.657895</td>\n      <td>50423</td>\n      <td>44</td>\n      <td>34</td>\n      <td>75</td>\n      <td>0.688073</td>\n      <td>0.630252</td>\n    </tr>\n    <tr>\n      <th>9314</th>\n      <td>2386-ch</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>5.635452</td>\n      <td>0.649351</td>\n      <td>50420</td>\n      <td>47</td>\n      <td>34</td>\n      <td>75</td>\n      <td>0.688073</td>\n      <td>0.614754</td>\n    </tr>\n    <tr>\n      <th>9317</th>\n      <td>2386-ch</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>6.628763</td>\n      <td>0.639175</td>\n      <td>50444</td>\n      <td>23</td>\n      <td>47</td>\n      <td>62</td>\n      <td>0.568807</td>\n      <td>0.729412</td>\n    </tr>\n    <tr>\n      <th>4811</th>\n      <td>2386-ch</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>4.642140</td>\n      <td>0.447917</td>\n      <td>50278</td>\n      <td>189</td>\n      <td>23</td>\n      <td>86</td>\n      <td>0.788991</td>\n      <td>0.312727</td>\n    </tr>\n    <tr>\n      <th>4812</th>\n      <td>2386-ch</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>4.973244</td>\n      <td>0.443804</td>\n      <td>50306</td>\n      <td>161</td>\n      <td>32</td>\n      <td>77</td>\n      <td>0.706422</td>\n      <td>0.323529</td>\n    </tr>\n    <tr>\n      <th>4813</th>\n      <td>2386-ch</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>5.304348</td>\n      <td>0.429907</td>\n      <td>50324</td>\n      <td>143</td>\n      <td>40</td>\n      <td>69</td>\n      <td>0.633028</td>\n      <td>0.325472</td>\n    </tr>\n    <tr>\n      <th>800109</th>\n      <td>2386-ch</td>\n      <td>50.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>3.979933</td>\n      <td>0.327273</td>\n      <td>50438</td>\n      <td>29</td>\n      <td>82</td>\n      <td>27</td>\n      <td>0.247706</td>\n      <td>0.482143</td>\n    </tr>\n    <tr>\n      <th>50109</th>\n      <td>2386-ch</td>\n      <td>50.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>3.979933</td>\n      <td>0.327273</td>\n      <td>50438</td>\n      <td>29</td>\n      <td>82</td>\n      <td>27</td>\n      <td>0.247706</td>\n      <td>0.482143</td>\n    </tr>\n    <tr>\n      <th>769208</th>\n      <td>2386-ch</td>\n      <td>49.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>3.648829</td>\n      <td>0.306931</td>\n      <td>50405</td>\n      <td>62</td>\n      <td>78</td>\n      <td>31</td>\n      <td>0.284404</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>19208</th>\n      <td>2386-ch</td>\n      <td>49.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.306931</td>\n      <td>50405</td>\n      <td>62</td>\n      <td>78</td>\n      <td>31</td>\n      <td>0.284404</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>80108</th>\n      <td>2386-ch</td>\n      <td>48.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.305419</td>\n      <td>50404</td>\n      <td>63</td>\n      <td>78</td>\n      <td>31</td>\n      <td>0.284404</td>\n      <td>0.329787</td>\n    </tr>\n    <tr>\n      <th>800108</th>\n      <td>2386-ch</td>\n      <td>50.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>3.648829</td>\n      <td>0.303922</td>\n      <td>50403</td>\n      <td>64</td>\n      <td>78</td>\n      <td>31</td>\n      <td>0.284404</td>\n      <td>0.326316</td>\n    </tr>\n    <tr>\n      <th>751800</th>\n      <td>2386-ch</td>\n      <td>47.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>814533</th>\n      <td>2386-ch</td>\n      <td>42.0</td>\n      <td>False</td>\n      <td>median</td>\n      <td>True</td>\n      <td>11.926421</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>814524</th>\n      <td>2386-ch</td>\n      <td>42.0</td>\n      <td>False</td>\n      <td>median</td>\n      <td>True</td>\n      <td>8.946488</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>861670</th>\n      <td>2386-ch</td>\n      <td>49.0</td>\n      <td>False</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>24.177258</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>798625</th>\n      <td>2386-ch</td>\n      <td>34.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>9.277592</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>798618</th>\n      <td>2386-ch</td>\n      <td>34.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>6.959866</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>888783</th>\n      <td>2386-ch</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>61.591973</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>803091</th>\n      <td>2386-ch</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>97.351171</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>803093</th>\n      <td>2386-ch</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>98.013378</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>138783</th>\n      <td>2386-ch</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>61.591973</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>53091</th>\n      <td>2386-ch</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>97.351171</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>53093</th>\n      <td>2386-ch</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>98.013378</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>755400</th>\n      <td>2386-ch</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>825603</th>\n      <td>2386-ch</td>\n      <td>11.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>825372</th>\n      <td>2386-ch</td>\n      <td>34.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>24.839465</td>\n      <td>0.120690</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>7</td>\n      <td>0.064220</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>5400</th>\n      <td>2386-ch</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>1.000000</td>\n      <td>0.004301</td>\n      <td>0</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>109</td>\n      <td>1.000000</td>\n      <td>0.002155</td>\n    </tr>\n    <tr>\n      <th>82212</th>\n      <td>2386-ch</td>\n      <td>27.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>4.973244</td>\n      <td>0.004301</td>\n      <td>0</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>109</td>\n      <td>1.000000</td>\n      <td>0.002155</td>\n    </tr>\n    <tr>\n      <th>82214</th>\n      <td>2386-ch</td>\n      <td>27.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>5.635452</td>\n      <td>0.004301</td>\n      <td>0</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>109</td>\n      <td>1.000000</td>\n      <td>0.002155</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_id = '2386-ch'\n",
    "tex_table_path = f'../bachelor-thesis/tables/{common_id}/'\n",
    "model_types = prediction_summaries_dict[common_id]['regular']['model_type'].unique()\n",
    "combined_df_lst = []\n",
    "for model_type in model_types:\n",
    "    tmp_df = prediction_summaries_dict[common_id]['regular']\n",
    "    norm_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (tmp_df['normalized'])]\n",
    "    combined_df_lst.append(norm_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "    reg_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (~tmp_df['normalized'])]\n",
    "    combined_df_lst.append(reg_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "combined_df = pd.concat(combined_df_lst).sort_values(by=['f1_score', 'model_type'], ascending=False)\n",
    "combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(\n",
    "    f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n",
    "    label=f'table:{common_id}-top-predictions-summary', index=False,\n",
    "    caption=f'Top predictions summary of {stations_dict[common_id][\"water_name\"]} - {stations_dict[common_id][\"station_name\"]}')\n",
    "combined_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "       common_id  window_size  center_window   model_type  normalized  \\\n9315     2386-ch          3.0           True       median       False   \n9314     2386-ch          3.0           True       median       False   \n9313     2386-ch          3.0           True       median       False   \n4811     2386-ch          3.0           True         mean       False   \n4812     2386-ch          3.0           True         mean       False   \n4813     2386-ch          3.0           True         mean       False   \n876600   2386-ch          5.0           True       median        True   \n811200   2386-ch          7.0           True       median        True   \n830400   2386-ch          6.0           True       median        True   \n800109   2386-ch         50.0           True      z-score        True   \n50109    2386-ch         50.0           True      z-score       False   \n769800   2386-ch          5.0           True         mean        True   \n897300   2386-ch          6.0           True         mean        True   \n769208   2386-ch         49.0           True      z-score        True   \n19208    2386-ch         49.0           True      z-score       False   \n80108    2386-ch         48.0           True      z-score       False   \n800108   2386-ch         50.0           True      z-score        True   \n777300   2386-ch          7.0           True         mean        True   \n784506   2386-ch         50.0           True  mad-z-score        True   \n34506    2386-ch         50.0           True  mad-z-score       False   \n849006   2386-ch         48.0           True  mad-z-score        True   \n99006    2386-ch         48.0           True  mad-z-score       False   \n869706   2386-ch         46.0           True  mad-z-score        True   \n119706   2386-ch         46.0           True  mad-z-score       False   \n852003   2386-ch         46.0          False          mad        True   \n823203   2386-ch         48.0          False          mad        True   \n796203   2386-ch         44.0          False          mad        True   \n5400     2386-ch          7.0           True          mad       False   \n104296   2386-ch         16.0           True          mad       False   \n104308   2386-ch         16.0           True          mad       False   \n\n        threshold  f1_score     tn     fp  fn   tp    recall  precision  \n9315     5.966555  0.635514  50423     44  34   68  0.666667   0.607143  \n9314     5.635452  0.626728  50420     47  34   68  0.666667   0.591304  \n9313     5.304348  0.613333  50413     54  33   69  0.676471   0.560976  \n4811     4.642140  0.441341  50290    177  23   79  0.774510   0.308594  \n4812     4.973244  0.436137  50318    149  32   70  0.686275   0.319635  \n4813     5.304348  0.420339  50336    131  40   62  0.607843   0.321244  \n876600   1.000000  0.381679  50463      4  77   25  0.245098   0.862069  \n811200   1.000000  0.374194  50443     24  73   29  0.284314   0.547170  \n830400   1.000000  0.363636  50434     33  72   30  0.294118   0.476190  \n800109   3.979933  0.320513  50438     29  77   25  0.245098   0.462963  \n50109    3.979933  0.320513  50438     29  77   25  0.245098   0.462963  \n769800   1.000000  0.312500  50434     33  77   25  0.245098   0.431034  \n897300   1.000000  0.311828  50412     55  73   29  0.284314   0.345238  \n769208   3.648829  0.300518  50405     62  73   29  0.284314   0.318681  \n19208    3.648829  0.300518  50405     62  73   29  0.284314   0.318681  \n80108    3.648829  0.298969  50404     63  73   29  0.284314   0.315217  \n800108   3.648829  0.297436  50403     64  73   29  0.284314   0.311828  \n777300   1.000000  0.293194  50406     61  74   28  0.274510   0.314607  \n784506   2.986622  0.034924  46574   3893  31   71  0.696078   0.017911  \n34506    2.986622  0.034924  46574   3893  31   71  0.696078   0.017911  \n849006   2.986622  0.033719  46487   3980  32   70  0.686275   0.017284  \n99006    2.986622  0.033719  46487   3980  32   70  0.686275   0.017284  \n869706   2.986622  0.033405  46448   4019  32   70  0.686275   0.017119  \n119706   2.986622  0.033405  46448   4019  32   70  0.686275   0.017119  \n852003   1.993311  0.027616  49212   1255  83   19  0.186275   0.014914  \n823203   1.993311  0.027556  49209   1258  83   19  0.186275   0.014879  \n796203   1.993311  0.027516  49207   1260  83   19  0.186275   0.014855  \n5400     1.000000  0.004026      0  50467   0  102  1.000000   0.002017  \n104296  65.896321  0.004026      0  50467   0  102  1.000000   0.002017  \n104308  69.869565  0.004026      0  50467   0  102  1.000000   0.002017  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>common_id</th>\n      <th>window_size</th>\n      <th>center_window</th>\n      <th>model_type</th>\n      <th>normalized</th>\n      <th>threshold</th>\n      <th>f1_score</th>\n      <th>tn</th>\n      <th>fp</th>\n      <th>fn</th>\n      <th>tp</th>\n      <th>recall</th>\n      <th>precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9315</th>\n      <td>2386-ch</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>5.966555</td>\n      <td>0.635514</td>\n      <td>50423</td>\n      <td>44</td>\n      <td>34</td>\n      <td>68</td>\n      <td>0.666667</td>\n      <td>0.607143</td>\n    </tr>\n    <tr>\n      <th>9314</th>\n      <td>2386-ch</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>5.635452</td>\n      <td>0.626728</td>\n      <td>50420</td>\n      <td>47</td>\n      <td>34</td>\n      <td>68</td>\n      <td>0.666667</td>\n      <td>0.591304</td>\n    </tr>\n    <tr>\n      <th>9313</th>\n      <td>2386-ch</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>5.304348</td>\n      <td>0.613333</td>\n      <td>50413</td>\n      <td>54</td>\n      <td>33</td>\n      <td>69</td>\n      <td>0.676471</td>\n      <td>0.560976</td>\n    </tr>\n    <tr>\n      <th>4811</th>\n      <td>2386-ch</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>4.642140</td>\n      <td>0.441341</td>\n      <td>50290</td>\n      <td>177</td>\n      <td>23</td>\n      <td>79</td>\n      <td>0.774510</td>\n      <td>0.308594</td>\n    </tr>\n    <tr>\n      <th>4812</th>\n      <td>2386-ch</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>4.973244</td>\n      <td>0.436137</td>\n      <td>50318</td>\n      <td>149</td>\n      <td>32</td>\n      <td>70</td>\n      <td>0.686275</td>\n      <td>0.319635</td>\n    </tr>\n    <tr>\n      <th>4813</th>\n      <td>2386-ch</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>5.304348</td>\n      <td>0.420339</td>\n      <td>50336</td>\n      <td>131</td>\n      <td>40</td>\n      <td>62</td>\n      <td>0.607843</td>\n      <td>0.321244</td>\n    </tr>\n    <tr>\n      <th>876600</th>\n      <td>2386-ch</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.381679</td>\n      <td>50463</td>\n      <td>4</td>\n      <td>77</td>\n      <td>25</td>\n      <td>0.245098</td>\n      <td>0.862069</td>\n    </tr>\n    <tr>\n      <th>811200</th>\n      <td>2386-ch</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.374194</td>\n      <td>50443</td>\n      <td>24</td>\n      <td>73</td>\n      <td>29</td>\n      <td>0.284314</td>\n      <td>0.547170</td>\n    </tr>\n    <tr>\n      <th>830400</th>\n      <td>2386-ch</td>\n      <td>6.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.363636</td>\n      <td>50434</td>\n      <td>33</td>\n      <td>72</td>\n      <td>30</td>\n      <td>0.294118</td>\n      <td>0.476190</td>\n    </tr>\n    <tr>\n      <th>800109</th>\n      <td>2386-ch</td>\n      <td>50.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>3.979933</td>\n      <td>0.320513</td>\n      <td>50438</td>\n      <td>29</td>\n      <td>77</td>\n      <td>25</td>\n      <td>0.245098</td>\n      <td>0.462963</td>\n    </tr>\n    <tr>\n      <th>50109</th>\n      <td>2386-ch</td>\n      <td>50.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>3.979933</td>\n      <td>0.320513</td>\n      <td>50438</td>\n      <td>29</td>\n      <td>77</td>\n      <td>25</td>\n      <td>0.245098</td>\n      <td>0.462963</td>\n    </tr>\n    <tr>\n      <th>769800</th>\n      <td>2386-ch</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.312500</td>\n      <td>50434</td>\n      <td>33</td>\n      <td>77</td>\n      <td>25</td>\n      <td>0.245098</td>\n      <td>0.431034</td>\n    </tr>\n    <tr>\n      <th>897300</th>\n      <td>2386-ch</td>\n      <td>6.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.311828</td>\n      <td>50412</td>\n      <td>55</td>\n      <td>73</td>\n      <td>29</td>\n      <td>0.284314</td>\n      <td>0.345238</td>\n    </tr>\n    <tr>\n      <th>769208</th>\n      <td>2386-ch</td>\n      <td>49.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>3.648829</td>\n      <td>0.300518</td>\n      <td>50405</td>\n      <td>62</td>\n      <td>73</td>\n      <td>29</td>\n      <td>0.284314</td>\n      <td>0.318681</td>\n    </tr>\n    <tr>\n      <th>19208</th>\n      <td>2386-ch</td>\n      <td>49.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.300518</td>\n      <td>50405</td>\n      <td>62</td>\n      <td>73</td>\n      <td>29</td>\n      <td>0.284314</td>\n      <td>0.318681</td>\n    </tr>\n    <tr>\n      <th>80108</th>\n      <td>2386-ch</td>\n      <td>48.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.298969</td>\n      <td>50404</td>\n      <td>63</td>\n      <td>73</td>\n      <td>29</td>\n      <td>0.284314</td>\n      <td>0.315217</td>\n    </tr>\n    <tr>\n      <th>800108</th>\n      <td>2386-ch</td>\n      <td>50.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>3.648829</td>\n      <td>0.297436</td>\n      <td>50403</td>\n      <td>64</td>\n      <td>73</td>\n      <td>29</td>\n      <td>0.284314</td>\n      <td>0.311828</td>\n    </tr>\n    <tr>\n      <th>777300</th>\n      <td>2386-ch</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.293194</td>\n      <td>50406</td>\n      <td>61</td>\n      <td>74</td>\n      <td>28</td>\n      <td>0.274510</td>\n      <td>0.314607</td>\n    </tr>\n    <tr>\n      <th>784506</th>\n      <td>2386-ch</td>\n      <td>50.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>2.986622</td>\n      <td>0.034924</td>\n      <td>46574</td>\n      <td>3893</td>\n      <td>31</td>\n      <td>71</td>\n      <td>0.696078</td>\n      <td>0.017911</td>\n    </tr>\n    <tr>\n      <th>34506</th>\n      <td>2386-ch</td>\n      <td>50.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>2.986622</td>\n      <td>0.034924</td>\n      <td>46574</td>\n      <td>3893</td>\n      <td>31</td>\n      <td>71</td>\n      <td>0.696078</td>\n      <td>0.017911</td>\n    </tr>\n    <tr>\n      <th>849006</th>\n      <td>2386-ch</td>\n      <td>48.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>2.986622</td>\n      <td>0.033719</td>\n      <td>46487</td>\n      <td>3980</td>\n      <td>32</td>\n      <td>70</td>\n      <td>0.686275</td>\n      <td>0.017284</td>\n    </tr>\n    <tr>\n      <th>99006</th>\n      <td>2386-ch</td>\n      <td>48.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>2.986622</td>\n      <td>0.033719</td>\n      <td>46487</td>\n      <td>3980</td>\n      <td>32</td>\n      <td>70</td>\n      <td>0.686275</td>\n      <td>0.017284</td>\n    </tr>\n    <tr>\n      <th>869706</th>\n      <td>2386-ch</td>\n      <td>46.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>2.986622</td>\n      <td>0.033405</td>\n      <td>46448</td>\n      <td>4019</td>\n      <td>32</td>\n      <td>70</td>\n      <td>0.686275</td>\n      <td>0.017119</td>\n    </tr>\n    <tr>\n      <th>119706</th>\n      <td>2386-ch</td>\n      <td>46.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>2.986622</td>\n      <td>0.033405</td>\n      <td>46448</td>\n      <td>4019</td>\n      <td>32</td>\n      <td>70</td>\n      <td>0.686275</td>\n      <td>0.017119</td>\n    </tr>\n    <tr>\n      <th>852003</th>\n      <td>2386-ch</td>\n      <td>46.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.027616</td>\n      <td>49212</td>\n      <td>1255</td>\n      <td>83</td>\n      <td>19</td>\n      <td>0.186275</td>\n      <td>0.014914</td>\n    </tr>\n    <tr>\n      <th>823203</th>\n      <td>2386-ch</td>\n      <td>48.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.027556</td>\n      <td>49209</td>\n      <td>1258</td>\n      <td>83</td>\n      <td>19</td>\n      <td>0.186275</td>\n      <td>0.014879</td>\n    </tr>\n    <tr>\n      <th>796203</th>\n      <td>2386-ch</td>\n      <td>44.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.027516</td>\n      <td>49207</td>\n      <td>1260</td>\n      <td>83</td>\n      <td>19</td>\n      <td>0.186275</td>\n      <td>0.014855</td>\n    </tr>\n    <tr>\n      <th>5400</th>\n      <td>2386-ch</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>1.000000</td>\n      <td>0.004026</td>\n      <td>0</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>1.000000</td>\n      <td>0.002017</td>\n    </tr>\n    <tr>\n      <th>104296</th>\n      <td>2386-ch</td>\n      <td>16.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>65.896321</td>\n      <td>0.004026</td>\n      <td>0</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>1.000000</td>\n      <td>0.002017</td>\n    </tr>\n    <tr>\n      <th>104308</th>\n      <td>2386-ch</td>\n      <td>16.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>69.869565</td>\n      <td>0.004026</td>\n      <td>0</td>\n      <td>50467</td>\n      <td>0</td>\n      <td>102</td>\n      <td>1.000000</td>\n      <td>0.002017</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_id = '2386-ch'\n",
    "tex_table_path = f'../bachelor-thesis/tables/{common_id}/'\n",
    "model_types = prediction_summaries_dict[common_id]['preprocessed']['model_type'].unique()\n",
    "combined_df_lst = []\n",
    "for model_type in model_types:\n",
    "    tmp_df = prediction_summaries_dict[common_id]['preprocessed']\n",
    "    norm_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (tmp_df['normalized'])]\n",
    "    combined_df_lst.append(norm_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "    reg_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (~tmp_df['normalized'])]\n",
    "    combined_df_lst.append(reg_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "combined_df = pd.concat(combined_df_lst).sort_values(by=['f1_score', 'model_type'], ascending=False)\n",
    "# combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(\n",
    "#     f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n",
    "#     label=f'table:{common_id}-top-predictions-summary', index=False,\n",
    "#     caption=f'Top predictions summary of {stations_dict[common_id][\"water_name\"]} - {stations_dict[common_id][\"station_name\"]}')\n",
    "combined_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_274729/567968503.py:12: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n"
     ]
    },
    {
     "data": {
      "text/plain": "             common_id  window_size  center_window   model_type  normalized  \\\n609322   2720050000-de          3.0           True       median       False   \n609323   2720050000-de          3.0           True       median       False   \n609324   2720050000-de          3.0           True       median       False   \n700208   2720050000-de         29.0           True      z-score       False   \n637207   2720050000-de         23.0           True      z-score       False   \n645908   2720050000-de         27.0           True      z-score       False   \n1392607  2720050000-de         22.0           True      z-score        True   \n1375808  2720050000-de         28.0           True      z-score        True   \n1352107  2720050000-de         20.0           True      z-score        True   \n604819   2720050000-de          3.0           True         mean       False   \n604818   2720050000-de          3.0           True         mean       False   \n604817   2720050000-de          3.0           True         mean       False   \n1488629  2720050000-de          NaN           True  mad-z-score        True   \n1402829  2720050000-de          NaN          False  mad-z-score        True   \n738629   2720050000-de          NaN           True  mad-z-score       False   \n652829   2720050000-de          NaN          False  mad-z-score       False   \n1488628  2720050000-de          NaN           True  mad-z-score        True   \n738628   2720050000-de          NaN           True  mad-z-score       False   \n1351800  2720050000-de         47.0           True       median        True   \n1419900  2720050000-de         29.0          False       median        True   \n1395304  2720050000-de         50.0          False       median        True   \n1385402  2720050000-de          NaN          False         mean        True   \n1444802  2720050000-de          NaN           True         mean        True   \n1444800  2720050000-de          NaN           True         mean        True   \n1355400  2720050000-de          7.0           True          mad        True   \n1434000  2720050000-de         31.0           True          mad        True   \n1407304  2720050000-de         25.0          False          mad        True   \n703199   2720050000-de         49.0           True          mad       False   \n699599   2720050000-de         50.0           True          mad       False   \n736499   2720050000-de         47.0           True          mad       False   \n\n          threshold  f1_score     tn    fp  fn  tp    recall  precision  \n609322     8.284281  0.905109  49447     5   8  62  0.885714   0.925373  \n609323     8.615385  0.905109  49447     5   8  62  0.885714   0.925373  \n609324     8.946488  0.905109  49447     5   8  62  0.885714   0.925373  \n700208     3.648829  0.545455  49434    18  37  33  0.471429   0.647059  \n637207     3.317726  0.545455  49434    18  37  33  0.471429   0.647059  \n645908     3.648829  0.542373  49436    16  38  32  0.457143   0.666667  \n1392607    3.317726  0.533333  49434    18  38  32  0.457143   0.640000  \n1375808    3.648829  0.533333  49434    18  38  32  0.457143   0.640000  \n1352107    3.317726  0.516667  49433    19  39  31  0.442857   0.620000  \n604819     7.290970  0.510288  49341   111   8  62  0.885714   0.358382  \n604818     6.959866  0.510121  49338   114   7  63  0.900000   0.355932  \n604817     6.628763  0.503937  49332   120   6  64  0.914286   0.347826  \n1488629   10.602007  0.133333  49452     0  65   5  0.071429   1.000000  \n1402829   10.602007  0.133333  49452     0  65   5  0.071429   1.000000  \n738629    10.602007  0.133333  49452     0  65   5  0.071429   1.000000  \n652829    10.602007  0.133333  49452     0  65   5  0.071429   1.000000  \n1488628   10.270903  0.119048  49443     9  65   5  0.071429   0.357143  \n738628    10.270903  0.119048  49443     9  65   5  0.071429   0.357143  \n1351800    1.000000  0.108108  49452     0  66   4  0.057143   1.000000  \n1419900    1.000000  0.108108  49452     0  66   4  0.057143   1.000000  \n1395304    2.324415  0.108108  49452     0  66   4  0.057143   1.000000  \n1385402    1.662207  0.108108  49452     0  66   4  0.057143   1.000000  \n1444802    1.662207  0.108108  49452     0  66   4  0.057143   1.000000  \n1444800    1.000000  0.108108  49452     0  66   4  0.057143   1.000000  \n1355400    1.000000  0.108108  49452     0  66   4  0.057143   1.000000  \n1434000    1.000000  0.108108  49452     0  66   4  0.057143   1.000000  \n1407304    2.324415  0.108108  49452     0  66   4  0.057143   1.000000  \n703199   100.000000  0.006390  43594  5858  51  19  0.271429   0.003233  \n699599   100.000000  0.006379  43584  5868  51  19  0.271429   0.003227  \n736499   100.000000  0.006360  43566  5886  51  19  0.271429   0.003218  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>common_id</th>\n      <th>window_size</th>\n      <th>center_window</th>\n      <th>model_type</th>\n      <th>normalized</th>\n      <th>threshold</th>\n      <th>f1_score</th>\n      <th>tn</th>\n      <th>fp</th>\n      <th>fn</th>\n      <th>tp</th>\n      <th>recall</th>\n      <th>precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>609322</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>8.284281</td>\n      <td>0.905109</td>\n      <td>49447</td>\n      <td>5</td>\n      <td>8</td>\n      <td>62</td>\n      <td>0.885714</td>\n      <td>0.925373</td>\n    </tr>\n    <tr>\n      <th>609323</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>8.615385</td>\n      <td>0.905109</td>\n      <td>49447</td>\n      <td>5</td>\n      <td>8</td>\n      <td>62</td>\n      <td>0.885714</td>\n      <td>0.925373</td>\n    </tr>\n    <tr>\n      <th>609324</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>8.946488</td>\n      <td>0.905109</td>\n      <td>49447</td>\n      <td>5</td>\n      <td>8</td>\n      <td>62</td>\n      <td>0.885714</td>\n      <td>0.925373</td>\n    </tr>\n    <tr>\n      <th>700208</th>\n      <td>2720050000-de</td>\n      <td>29.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.545455</td>\n      <td>49434</td>\n      <td>18</td>\n      <td>37</td>\n      <td>33</td>\n      <td>0.471429</td>\n      <td>0.647059</td>\n    </tr>\n    <tr>\n      <th>637207</th>\n      <td>2720050000-de</td>\n      <td>23.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>3.317726</td>\n      <td>0.545455</td>\n      <td>49434</td>\n      <td>18</td>\n      <td>37</td>\n      <td>33</td>\n      <td>0.471429</td>\n      <td>0.647059</td>\n    </tr>\n    <tr>\n      <th>645908</th>\n      <td>2720050000-de</td>\n      <td>27.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.542373</td>\n      <td>49436</td>\n      <td>16</td>\n      <td>38</td>\n      <td>32</td>\n      <td>0.457143</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>1392607</th>\n      <td>2720050000-de</td>\n      <td>22.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>3.317726</td>\n      <td>0.533333</td>\n      <td>49434</td>\n      <td>18</td>\n      <td>38</td>\n      <td>32</td>\n      <td>0.457143</td>\n      <td>0.640000</td>\n    </tr>\n    <tr>\n      <th>1375808</th>\n      <td>2720050000-de</td>\n      <td>28.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>3.648829</td>\n      <td>0.533333</td>\n      <td>49434</td>\n      <td>18</td>\n      <td>38</td>\n      <td>32</td>\n      <td>0.457143</td>\n      <td>0.640000</td>\n    </tr>\n    <tr>\n      <th>1352107</th>\n      <td>2720050000-de</td>\n      <td>20.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>3.317726</td>\n      <td>0.516667</td>\n      <td>49433</td>\n      <td>19</td>\n      <td>39</td>\n      <td>31</td>\n      <td>0.442857</td>\n      <td>0.620000</td>\n    </tr>\n    <tr>\n      <th>604819</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>7.290970</td>\n      <td>0.510288</td>\n      <td>49341</td>\n      <td>111</td>\n      <td>8</td>\n      <td>62</td>\n      <td>0.885714</td>\n      <td>0.358382</td>\n    </tr>\n    <tr>\n      <th>604818</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>6.959866</td>\n      <td>0.510121</td>\n      <td>49338</td>\n      <td>114</td>\n      <td>7</td>\n      <td>63</td>\n      <td>0.900000</td>\n      <td>0.355932</td>\n    </tr>\n    <tr>\n      <th>604817</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>6.628763</td>\n      <td>0.503937</td>\n      <td>49332</td>\n      <td>120</td>\n      <td>6</td>\n      <td>64</td>\n      <td>0.914286</td>\n      <td>0.347826</td>\n    </tr>\n    <tr>\n      <th>1488629</th>\n      <td>2720050000-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>10.602007</td>\n      <td>0.133333</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>65</td>\n      <td>5</td>\n      <td>0.071429</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1402829</th>\n      <td>2720050000-de</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>10.602007</td>\n      <td>0.133333</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>65</td>\n      <td>5</td>\n      <td>0.071429</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>738629</th>\n      <td>2720050000-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>10.602007</td>\n      <td>0.133333</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>65</td>\n      <td>5</td>\n      <td>0.071429</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>652829</th>\n      <td>2720050000-de</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>10.602007</td>\n      <td>0.133333</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>65</td>\n      <td>5</td>\n      <td>0.071429</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1488628</th>\n      <td>2720050000-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>10.270903</td>\n      <td>0.119048</td>\n      <td>49443</td>\n      <td>9</td>\n      <td>65</td>\n      <td>5</td>\n      <td>0.071429</td>\n      <td>0.357143</td>\n    </tr>\n    <tr>\n      <th>738628</th>\n      <td>2720050000-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>10.270903</td>\n      <td>0.119048</td>\n      <td>49443</td>\n      <td>9</td>\n      <td>65</td>\n      <td>5</td>\n      <td>0.071429</td>\n      <td>0.357143</td>\n    </tr>\n    <tr>\n      <th>1351800</th>\n      <td>2720050000-de</td>\n      <td>47.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.108108</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>66</td>\n      <td>4</td>\n      <td>0.057143</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1419900</th>\n      <td>2720050000-de</td>\n      <td>29.0</td>\n      <td>False</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.108108</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>66</td>\n      <td>4</td>\n      <td>0.057143</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1395304</th>\n      <td>2720050000-de</td>\n      <td>50.0</td>\n      <td>False</td>\n      <td>median</td>\n      <td>True</td>\n      <td>2.324415</td>\n      <td>0.108108</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>66</td>\n      <td>4</td>\n      <td>0.057143</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1385402</th>\n      <td>2720050000-de</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.662207</td>\n      <td>0.108108</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>66</td>\n      <td>4</td>\n      <td>0.057143</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1444802</th>\n      <td>2720050000-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.662207</td>\n      <td>0.108108</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>66</td>\n      <td>4</td>\n      <td>0.057143</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1444800</th>\n      <td>2720050000-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.108108</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>66</td>\n      <td>4</td>\n      <td>0.057143</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1355400</th>\n      <td>2720050000-de</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.108108</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>66</td>\n      <td>4</td>\n      <td>0.057143</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1434000</th>\n      <td>2720050000-de</td>\n      <td>31.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.108108</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>66</td>\n      <td>4</td>\n      <td>0.057143</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1407304</th>\n      <td>2720050000-de</td>\n      <td>25.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>2.324415</td>\n      <td>0.108108</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>66</td>\n      <td>4</td>\n      <td>0.057143</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>703199</th>\n      <td>2720050000-de</td>\n      <td>49.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>100.000000</td>\n      <td>0.006390</td>\n      <td>43594</td>\n      <td>5858</td>\n      <td>51</td>\n      <td>19</td>\n      <td>0.271429</td>\n      <td>0.003233</td>\n    </tr>\n    <tr>\n      <th>699599</th>\n      <td>2720050000-de</td>\n      <td>50.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>100.000000</td>\n      <td>0.006379</td>\n      <td>43584</td>\n      <td>5868</td>\n      <td>51</td>\n      <td>19</td>\n      <td>0.271429</td>\n      <td>0.003227</td>\n    </tr>\n    <tr>\n      <th>736499</th>\n      <td>2720050000-de</td>\n      <td>47.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>100.000000</td>\n      <td>0.006360</td>\n      <td>43566</td>\n      <td>5886</td>\n      <td>51</td>\n      <td>19</td>\n      <td>0.271429</td>\n      <td>0.003218</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_id = '2720050000-de'\n",
    "tex_table_path = f'../bachelor-thesis/tables/{common_id}/'\n",
    "model_types = prediction_summaries_dict[common_id]['regular']['model_type'].unique()\n",
    "combined_df_lst = []\n",
    "for model_type in model_types:\n",
    "    tmp_df = prediction_summaries_dict[common_id]['regular']\n",
    "    norm_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (tmp_df['normalized'])]\n",
    "    combined_df_lst.append(norm_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "    reg_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (~tmp_df['normalized'])]\n",
    "    combined_df_lst.append(reg_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "combined_df = pd.concat(combined_df_lst).sort_values(by=['f1_score', 'model_type'], ascending=False)\n",
    "combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(\n",
    "    f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n",
    "    label=f'table:{common_id}-top-predictions-summary', index=False,\n",
    "    caption=f'Top predictions summary of {stations_dict[common_id][\"water_name\"]} - {stations_dict[common_id][\"station_name\"]}')\n",
    "combined_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "             common_id  window_size  center_window   model_type  normalized  \\\n609324   2720050000-de          3.0           True       median       False   \n609323   2720050000-de          3.0           True       median       False   \n609322   2720050000-de          3.0           True       median       False   \n637207   2720050000-de         23.0           True      z-score       False   \n700208   2720050000-de         29.0           True      z-score       False   \n645908   2720050000-de         27.0           True      z-score       False   \n1351507  2720050000-de         21.0           True      z-score        True   \n1351508  2720050000-de         21.0           True      z-score        True   \n604819   2720050000-de          3.0           True         mean       False   \n604818   2720050000-de          3.0           True         mean       False   \n1466109  2720050000-de         32.0           True      z-score        True   \n604817   2720050000-de          3.0           True         mean       False   \n1359300  2720050000-de          3.0           True       median        True   \n1359301  2720050000-de          3.0           True       median        True   \n1476601  2720050000-de          5.0           True       median        True   \n1463701  2720050000-de         11.0           True         mean        True   \n1377300  2720050000-de          7.0           True         mean        True   \n1411501  2720050000-de         13.0           True         mean        True   \n1392004  2720050000-de          4.0           True  mad-z-score        True   \n642004   2720050000-de          4.0           True  mad-z-score       False   \n1392007  2720050000-de          4.0           True  mad-z-score        True   \n642007   2720050000-de          4.0           True  mad-z-score       False   \n1392005  2720050000-de          4.0           True  mad-z-score        True   \n642005   2720050000-de          4.0           True  mad-z-score       False   \n1448418  2720050000-de         15.0          False          mad        True   \n1453218  2720050000-de         17.0           True          mad        True   \n1375517  2720050000-de         40.0          False          mad        True   \n703199   2720050000-de         49.0           True          mad       False   \n699599   2720050000-de         50.0           True          mad       False   \n736499   2720050000-de         47.0           True          mad       False   \n\n          threshold  f1_score     tn    fp  fn  tp    recall  precision  \n609324     8.946488  0.886957  49447     5   8  51  0.864407   0.910714  \n609323     8.615385  0.886957  49447     5   8  51  0.864407   0.910714  \n609322     8.284281  0.886957  49447     5   8  51  0.864407   0.910714  \n637207     3.317726  0.542056  49433    19  30  29  0.491525   0.604167  \n700208     3.648829  0.542056  49433    19  30  29  0.491525   0.604167  \n645908     3.648829  0.538462  49435    17  31  28  0.474576   0.622222  \n1351507    3.317726  0.519231  49434    18  32  27  0.457627   0.600000  \n1351508    3.648829  0.516129  49442    10  35  24  0.406780   0.705882  \n604819     7.290970  0.507463  49361    91   8  51  0.864407   0.359155  \n604818     6.959866  0.507317  49358    94   7  52  0.881356   0.356164  \n1466109    3.979933  0.505263  49440    12  35  24  0.406780   0.666667  \n604817     6.628763  0.500000  49352   100   6  53  0.898305   0.346405  \n1359300    1.000000  0.467532  49452     0  41  18  0.305085   1.000000  \n1359301    1.331104  0.467532  49452     0  41  18  0.305085   1.000000  \n1476601    1.331104  0.467532  49452     0  41  18  0.305085   1.000000  \n1463701    1.331104  0.461538  49451     1  41  18  0.305085   0.947368  \n1377300    1.000000  0.455696  49450     2  41  18  0.305085   0.900000  \n1411501    1.331104  0.455696  49450     2  41  18  0.305085   0.900000  \n1392004    2.324415  0.061050  47923  1529   9  50  0.847458   0.031666  \n642004     2.324415  0.061050  47923  1529   9  50  0.847458   0.031666  \n1392007    3.317726  0.059008  47965  1487  12  47  0.796610   0.030639  \n642007     3.317726  0.059008  47965  1487  12  47  0.796610   0.030639  \n1392005    2.655518  0.058968  47931  1521  11  48  0.813559   0.030593  \n642005     2.655518  0.058968  47931  1521  11  48  0.813559   0.030593  \n1448418    6.959866  0.033333  49452     0  58   1  0.016949   1.000000  \n1453218    6.959866  0.033333  49452     0  58   1  0.016949   1.000000  \n1375517    6.628763  0.033333  49452     0  58   1  0.016949   1.000000  \n703199   100.000000  0.005057  43594  5858  44  15  0.254237   0.002554  \n699599   100.000000  0.005048  43583  5869  44  15  0.254237   0.002549  \n736499   100.000000  0.005034  43566  5886  44  15  0.254237   0.002542  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>common_id</th>\n      <th>window_size</th>\n      <th>center_window</th>\n      <th>model_type</th>\n      <th>normalized</th>\n      <th>threshold</th>\n      <th>f1_score</th>\n      <th>tn</th>\n      <th>fp</th>\n      <th>fn</th>\n      <th>tp</th>\n      <th>recall</th>\n      <th>precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>609324</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>8.946488</td>\n      <td>0.886957</td>\n      <td>49447</td>\n      <td>5</td>\n      <td>8</td>\n      <td>51</td>\n      <td>0.864407</td>\n      <td>0.910714</td>\n    </tr>\n    <tr>\n      <th>609323</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>8.615385</td>\n      <td>0.886957</td>\n      <td>49447</td>\n      <td>5</td>\n      <td>8</td>\n      <td>51</td>\n      <td>0.864407</td>\n      <td>0.910714</td>\n    </tr>\n    <tr>\n      <th>609322</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>8.284281</td>\n      <td>0.886957</td>\n      <td>49447</td>\n      <td>5</td>\n      <td>8</td>\n      <td>51</td>\n      <td>0.864407</td>\n      <td>0.910714</td>\n    </tr>\n    <tr>\n      <th>637207</th>\n      <td>2720050000-de</td>\n      <td>23.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>3.317726</td>\n      <td>0.542056</td>\n      <td>49433</td>\n      <td>19</td>\n      <td>30</td>\n      <td>29</td>\n      <td>0.491525</td>\n      <td>0.604167</td>\n    </tr>\n    <tr>\n      <th>700208</th>\n      <td>2720050000-de</td>\n      <td>29.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.542056</td>\n      <td>49433</td>\n      <td>19</td>\n      <td>30</td>\n      <td>29</td>\n      <td>0.491525</td>\n      <td>0.604167</td>\n    </tr>\n    <tr>\n      <th>645908</th>\n      <td>2720050000-de</td>\n      <td>27.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.538462</td>\n      <td>49435</td>\n      <td>17</td>\n      <td>31</td>\n      <td>28</td>\n      <td>0.474576</td>\n      <td>0.622222</td>\n    </tr>\n    <tr>\n      <th>1351507</th>\n      <td>2720050000-de</td>\n      <td>21.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>3.317726</td>\n      <td>0.519231</td>\n      <td>49434</td>\n      <td>18</td>\n      <td>32</td>\n      <td>27</td>\n      <td>0.457627</td>\n      <td>0.600000</td>\n    </tr>\n    <tr>\n      <th>1351508</th>\n      <td>2720050000-de</td>\n      <td>21.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>3.648829</td>\n      <td>0.516129</td>\n      <td>49442</td>\n      <td>10</td>\n      <td>35</td>\n      <td>24</td>\n      <td>0.406780</td>\n      <td>0.705882</td>\n    </tr>\n    <tr>\n      <th>604819</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>7.290970</td>\n      <td>0.507463</td>\n      <td>49361</td>\n      <td>91</td>\n      <td>8</td>\n      <td>51</td>\n      <td>0.864407</td>\n      <td>0.359155</td>\n    </tr>\n    <tr>\n      <th>604818</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>6.959866</td>\n      <td>0.507317</td>\n      <td>49358</td>\n      <td>94</td>\n      <td>7</td>\n      <td>52</td>\n      <td>0.881356</td>\n      <td>0.356164</td>\n    </tr>\n    <tr>\n      <th>1466109</th>\n      <td>2720050000-de</td>\n      <td>32.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>3.979933</td>\n      <td>0.505263</td>\n      <td>49440</td>\n      <td>12</td>\n      <td>35</td>\n      <td>24</td>\n      <td>0.406780</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>604817</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>6.628763</td>\n      <td>0.500000</td>\n      <td>49352</td>\n      <td>100</td>\n      <td>6</td>\n      <td>53</td>\n      <td>0.898305</td>\n      <td>0.346405</td>\n    </tr>\n    <tr>\n      <th>1359300</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.467532</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>41</td>\n      <td>18</td>\n      <td>0.305085</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1359301</th>\n      <td>2720050000-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.331104</td>\n      <td>0.467532</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>41</td>\n      <td>18</td>\n      <td>0.305085</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1476601</th>\n      <td>2720050000-de</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.331104</td>\n      <td>0.467532</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>41</td>\n      <td>18</td>\n      <td>0.305085</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1463701</th>\n      <td>2720050000-de</td>\n      <td>11.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.331104</td>\n      <td>0.461538</td>\n      <td>49451</td>\n      <td>1</td>\n      <td>41</td>\n      <td>18</td>\n      <td>0.305085</td>\n      <td>0.947368</td>\n    </tr>\n    <tr>\n      <th>1377300</th>\n      <td>2720050000-de</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.455696</td>\n      <td>49450</td>\n      <td>2</td>\n      <td>41</td>\n      <td>18</td>\n      <td>0.305085</td>\n      <td>0.900000</td>\n    </tr>\n    <tr>\n      <th>1411501</th>\n      <td>2720050000-de</td>\n      <td>13.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.331104</td>\n      <td>0.455696</td>\n      <td>49450</td>\n      <td>2</td>\n      <td>41</td>\n      <td>18</td>\n      <td>0.305085</td>\n      <td>0.900000</td>\n    </tr>\n    <tr>\n      <th>1392004</th>\n      <td>2720050000-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>2.324415</td>\n      <td>0.061050</td>\n      <td>47923</td>\n      <td>1529</td>\n      <td>9</td>\n      <td>50</td>\n      <td>0.847458</td>\n      <td>0.031666</td>\n    </tr>\n    <tr>\n      <th>642004</th>\n      <td>2720050000-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>2.324415</td>\n      <td>0.061050</td>\n      <td>47923</td>\n      <td>1529</td>\n      <td>9</td>\n      <td>50</td>\n      <td>0.847458</td>\n      <td>0.031666</td>\n    </tr>\n    <tr>\n      <th>1392007</th>\n      <td>2720050000-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>3.317726</td>\n      <td>0.059008</td>\n      <td>47965</td>\n      <td>1487</td>\n      <td>12</td>\n      <td>47</td>\n      <td>0.796610</td>\n      <td>0.030639</td>\n    </tr>\n    <tr>\n      <th>642007</th>\n      <td>2720050000-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>3.317726</td>\n      <td>0.059008</td>\n      <td>47965</td>\n      <td>1487</td>\n      <td>12</td>\n      <td>47</td>\n      <td>0.796610</td>\n      <td>0.030639</td>\n    </tr>\n    <tr>\n      <th>1392005</th>\n      <td>2720050000-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>2.655518</td>\n      <td>0.058968</td>\n      <td>47931</td>\n      <td>1521</td>\n      <td>11</td>\n      <td>48</td>\n      <td>0.813559</td>\n      <td>0.030593</td>\n    </tr>\n    <tr>\n      <th>642005</th>\n      <td>2720050000-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>2.655518</td>\n      <td>0.058968</td>\n      <td>47931</td>\n      <td>1521</td>\n      <td>11</td>\n      <td>48</td>\n      <td>0.813559</td>\n      <td>0.030593</td>\n    </tr>\n    <tr>\n      <th>1448418</th>\n      <td>2720050000-de</td>\n      <td>15.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>6.959866</td>\n      <td>0.033333</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>58</td>\n      <td>1</td>\n      <td>0.016949</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1453218</th>\n      <td>2720050000-de</td>\n      <td>17.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>6.959866</td>\n      <td>0.033333</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>58</td>\n      <td>1</td>\n      <td>0.016949</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1375517</th>\n      <td>2720050000-de</td>\n      <td>40.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>6.628763</td>\n      <td>0.033333</td>\n      <td>49452</td>\n      <td>0</td>\n      <td>58</td>\n      <td>1</td>\n      <td>0.016949</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>703199</th>\n      <td>2720050000-de</td>\n      <td>49.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>100.000000</td>\n      <td>0.005057</td>\n      <td>43594</td>\n      <td>5858</td>\n      <td>44</td>\n      <td>15</td>\n      <td>0.254237</td>\n      <td>0.002554</td>\n    </tr>\n    <tr>\n      <th>699599</th>\n      <td>2720050000-de</td>\n      <td>50.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>100.000000</td>\n      <td>0.005048</td>\n      <td>43583</td>\n      <td>5869</td>\n      <td>44</td>\n      <td>15</td>\n      <td>0.254237</td>\n      <td>0.002549</td>\n    </tr>\n    <tr>\n      <th>736499</th>\n      <td>2720050000-de</td>\n      <td>47.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>100.000000</td>\n      <td>0.005034</td>\n      <td>43566</td>\n      <td>5886</td>\n      <td>44</td>\n      <td>15</td>\n      <td>0.254237</td>\n      <td>0.002542</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_id = '2720050000-de'\n",
    "tex_table_path = f'../bachelor-thesis/tables/{common_id}/'\n",
    "model_types = prediction_summaries_dict[common_id]['preprocessed']['model_type'].unique()\n",
    "combined_df_lst = []\n",
    "for model_type in model_types:\n",
    "    tmp_df = prediction_summaries_dict[common_id]['preprocessed']\n",
    "    norm_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (tmp_df['normalized'])]\n",
    "    combined_df_lst.append(norm_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "    reg_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (~tmp_df['normalized'])]\n",
    "    combined_df_lst.append(reg_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "combined_df = pd.concat(combined_df_lst).sort_values(by=['f1_score', 'model_type'], ascending=False)\n",
    "# combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(\n",
    "#     f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n",
    "#     label=f'table:{common_id}-top-predictions-summary', index=False,\n",
    "#     caption=f'Top predictions summary of {stations_dict[common_id][\"water_name\"]} - {stations_dict[common_id][\"station_name\"]}')\n",
    "combined_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_274729/2190905790.py:12: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n"
     ]
    },
    {
     "data": {
      "text/plain": "        common_id  window_size  center_window   model_type  normalized  \\\n276623   39003-ie          5.0           True       median       False   \n276625   39003-ie          5.0           True       median       False   \n276624   39003-ie          5.0           True       median       False   \n913808   39003-ie         34.0           True  mad-z-score        True   \n163808   39003-ie         34.0           True  mad-z-score       False   \n913810   39003-ie         34.0           True  mad-z-score        True   \n163810   39003-ie         34.0           True  mad-z-score       False   \n1017311  39003-ie         32.0           True  mad-z-score        True   \n267311   39003-ie         32.0           True  mad-z-score       False   \n951900   39003-ie         11.0           True       median        True   \n921300   39003-ie         10.0           True       median        True   \n926400   39003-ie          9.0           True       median        True   \n177349   39003-ie          7.0           True         mean       False   \n177346   39003-ie          7.0           True         mean       False   \n177348   39003-ie          7.0           True         mean       False   \n914403   39003-ie         26.0           True      z-score        True   \n164403   39003-ie         26.0           True      z-score       False   \n945903   39003-ie         27.0           True      z-score        True   \n195903   39003-ie         27.0           True      z-score       False   \n954003   39003-ie         25.0           True      z-score        True   \n204003   39003-ie         25.0           True      z-score       False   \n993300   39003-ie          8.0           True         mean        True   \n1035600  39003-ie          9.0           True         mean        True   \n1011300  39003-ie         10.0           True         mean        True   \n274755   39003-ie         36.0           True          mad       False   \n164955   39003-ie         34.0           True          mad       False   \n274754   39003-ie         36.0           True          mad       False   \n1032902  39003-ie         30.0           True          mad        True   \n1044602  39003-ie         14.0          False          mad        True   \n976802   39003-ie         29.0           True          mad        True   \n\n         threshold  f1_score     tn    fp   fn   tp    recall  precision  \n276623    8.615385  0.859035  27198    80   69  454  0.868069   0.850187  \n276625    9.277592  0.858500  27200    78   71  452  0.864245   0.852830  \n276624    8.946488  0.857685  27199    79   71  452  0.864245   0.851224  \n913808    3.648829  0.736842  27093   185  110  413  0.789675   0.690635  \n163808    3.648829  0.736842  27093   185  110  413  0.789675   0.690635  \n913810    4.311037  0.733962  27130   148  134  389  0.743786   0.724395  \n163810    4.311037  0.733962  27130   148  134  389  0.743786   0.724395  \n1017311   4.642140  0.731707  27125   153  133  390  0.745698   0.718232  \n267311    4.642140  0.731707  27125   153  133  390  0.745698   0.718232  \n951900    1.000000  0.723699  27249    29  210  313  0.598470   0.915205  \n921300    1.000000  0.723059  27250    28  211  312  0.596558   0.917647  \n926400    1.000000  0.720189  27259    19  218  305  0.583174   0.941358  \n177349   17.224080  0.684211  27151   127  185  338  0.646272   0.726882  \n177346   16.230769  0.683398  27119   159  169  354  0.676864   0.690058  \n177348   16.892977  0.683267  27140   138  180  343  0.655832   0.713098  \n914403    1.993311  0.677668  27200    78  215  308  0.588910   0.797927  \n164403    1.993311  0.677668  27200    78  215  308  0.588910   0.797927  \n945903    1.993311  0.672489  27193    85  215  308  0.588910   0.783715  \n195903    1.993311  0.672489  27193    85  215  308  0.588910   0.783715  \n954003    1.993311  0.669633  27203    75  222  301  0.575526   0.800532  \n204003    1.993311  0.669633  27203    75  222  301  0.575526   0.800532  \n993300    1.000000  0.643868  27226    52  250  273  0.521989   0.840000  \n1035600   1.000000  0.636678  27210    68  247  276  0.527725   0.802326  \n1011300   1.000000  0.633596  27195    83  242  281  0.537285   0.771978  \n274755   85.431438  0.180556  26229  1049  367  156  0.298279   0.129461  \n164955   85.431438  0.180149  26215  1063  366  157  0.300191   0.128689  \n274754   85.100334  0.179840  26212  1066  366  157  0.300191   0.128373  \n1032902   1.662207  0.173418  26358   920  386  137  0.261950   0.129612  \n1044602   1.662207  0.173355  26094  1184  361  162  0.309751   0.120357  \n976802    1.662207  0.173149  26345   933  385  138  0.263862   0.128852  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>common_id</th>\n      <th>window_size</th>\n      <th>center_window</th>\n      <th>model_type</th>\n      <th>normalized</th>\n      <th>threshold</th>\n      <th>f1_score</th>\n      <th>tn</th>\n      <th>fp</th>\n      <th>fn</th>\n      <th>tp</th>\n      <th>recall</th>\n      <th>precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>276623</th>\n      <td>39003-ie</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>8.615385</td>\n      <td>0.859035</td>\n      <td>27198</td>\n      <td>80</td>\n      <td>69</td>\n      <td>454</td>\n      <td>0.868069</td>\n      <td>0.850187</td>\n    </tr>\n    <tr>\n      <th>276625</th>\n      <td>39003-ie</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>9.277592</td>\n      <td>0.858500</td>\n      <td>27200</td>\n      <td>78</td>\n      <td>71</td>\n      <td>452</td>\n      <td>0.864245</td>\n      <td>0.852830</td>\n    </tr>\n    <tr>\n      <th>276624</th>\n      <td>39003-ie</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>8.946488</td>\n      <td>0.857685</td>\n      <td>27199</td>\n      <td>79</td>\n      <td>71</td>\n      <td>452</td>\n      <td>0.864245</td>\n      <td>0.851224</td>\n    </tr>\n    <tr>\n      <th>913808</th>\n      <td>39003-ie</td>\n      <td>34.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>3.648829</td>\n      <td>0.736842</td>\n      <td>27093</td>\n      <td>185</td>\n      <td>110</td>\n      <td>413</td>\n      <td>0.789675</td>\n      <td>0.690635</td>\n    </tr>\n    <tr>\n      <th>163808</th>\n      <td>39003-ie</td>\n      <td>34.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.736842</td>\n      <td>27093</td>\n      <td>185</td>\n      <td>110</td>\n      <td>413</td>\n      <td>0.789675</td>\n      <td>0.690635</td>\n    </tr>\n    <tr>\n      <th>913810</th>\n      <td>39003-ie</td>\n      <td>34.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>4.311037</td>\n      <td>0.733962</td>\n      <td>27130</td>\n      <td>148</td>\n      <td>134</td>\n      <td>389</td>\n      <td>0.743786</td>\n      <td>0.724395</td>\n    </tr>\n    <tr>\n      <th>163810</th>\n      <td>39003-ie</td>\n      <td>34.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>4.311037</td>\n      <td>0.733962</td>\n      <td>27130</td>\n      <td>148</td>\n      <td>134</td>\n      <td>389</td>\n      <td>0.743786</td>\n      <td>0.724395</td>\n    </tr>\n    <tr>\n      <th>1017311</th>\n      <td>39003-ie</td>\n      <td>32.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>4.642140</td>\n      <td>0.731707</td>\n      <td>27125</td>\n      <td>153</td>\n      <td>133</td>\n      <td>390</td>\n      <td>0.745698</td>\n      <td>0.718232</td>\n    </tr>\n    <tr>\n      <th>267311</th>\n      <td>39003-ie</td>\n      <td>32.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>4.642140</td>\n      <td>0.731707</td>\n      <td>27125</td>\n      <td>153</td>\n      <td>133</td>\n      <td>390</td>\n      <td>0.745698</td>\n      <td>0.718232</td>\n    </tr>\n    <tr>\n      <th>951900</th>\n      <td>39003-ie</td>\n      <td>11.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.723699</td>\n      <td>27249</td>\n      <td>29</td>\n      <td>210</td>\n      <td>313</td>\n      <td>0.598470</td>\n      <td>0.915205</td>\n    </tr>\n    <tr>\n      <th>921300</th>\n      <td>39003-ie</td>\n      <td>10.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.723059</td>\n      <td>27250</td>\n      <td>28</td>\n      <td>211</td>\n      <td>312</td>\n      <td>0.596558</td>\n      <td>0.917647</td>\n    </tr>\n    <tr>\n      <th>926400</th>\n      <td>39003-ie</td>\n      <td>9.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.720189</td>\n      <td>27259</td>\n      <td>19</td>\n      <td>218</td>\n      <td>305</td>\n      <td>0.583174</td>\n      <td>0.941358</td>\n    </tr>\n    <tr>\n      <th>177349</th>\n      <td>39003-ie</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>17.224080</td>\n      <td>0.684211</td>\n      <td>27151</td>\n      <td>127</td>\n      <td>185</td>\n      <td>338</td>\n      <td>0.646272</td>\n      <td>0.726882</td>\n    </tr>\n    <tr>\n      <th>177346</th>\n      <td>39003-ie</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>16.230769</td>\n      <td>0.683398</td>\n      <td>27119</td>\n      <td>159</td>\n      <td>169</td>\n      <td>354</td>\n      <td>0.676864</td>\n      <td>0.690058</td>\n    </tr>\n    <tr>\n      <th>177348</th>\n      <td>39003-ie</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>16.892977</td>\n      <td>0.683267</td>\n      <td>27140</td>\n      <td>138</td>\n      <td>180</td>\n      <td>343</td>\n      <td>0.655832</td>\n      <td>0.713098</td>\n    </tr>\n    <tr>\n      <th>914403</th>\n      <td>39003-ie</td>\n      <td>26.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.677668</td>\n      <td>27200</td>\n      <td>78</td>\n      <td>215</td>\n      <td>308</td>\n      <td>0.588910</td>\n      <td>0.797927</td>\n    </tr>\n    <tr>\n      <th>164403</th>\n      <td>39003-ie</td>\n      <td>26.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>1.993311</td>\n      <td>0.677668</td>\n      <td>27200</td>\n      <td>78</td>\n      <td>215</td>\n      <td>308</td>\n      <td>0.588910</td>\n      <td>0.797927</td>\n    </tr>\n    <tr>\n      <th>945903</th>\n      <td>39003-ie</td>\n      <td>27.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.672489</td>\n      <td>27193</td>\n      <td>85</td>\n      <td>215</td>\n      <td>308</td>\n      <td>0.588910</td>\n      <td>0.783715</td>\n    </tr>\n    <tr>\n      <th>195903</th>\n      <td>39003-ie</td>\n      <td>27.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>1.993311</td>\n      <td>0.672489</td>\n      <td>27193</td>\n      <td>85</td>\n      <td>215</td>\n      <td>308</td>\n      <td>0.588910</td>\n      <td>0.783715</td>\n    </tr>\n    <tr>\n      <th>954003</th>\n      <td>39003-ie</td>\n      <td>25.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.669633</td>\n      <td>27203</td>\n      <td>75</td>\n      <td>222</td>\n      <td>301</td>\n      <td>0.575526</td>\n      <td>0.800532</td>\n    </tr>\n    <tr>\n      <th>204003</th>\n      <td>39003-ie</td>\n      <td>25.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>1.993311</td>\n      <td>0.669633</td>\n      <td>27203</td>\n      <td>75</td>\n      <td>222</td>\n      <td>301</td>\n      <td>0.575526</td>\n      <td>0.800532</td>\n    </tr>\n    <tr>\n      <th>993300</th>\n      <td>39003-ie</td>\n      <td>8.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.643868</td>\n      <td>27226</td>\n      <td>52</td>\n      <td>250</td>\n      <td>273</td>\n      <td>0.521989</td>\n      <td>0.840000</td>\n    </tr>\n    <tr>\n      <th>1035600</th>\n      <td>39003-ie</td>\n      <td>9.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.636678</td>\n      <td>27210</td>\n      <td>68</td>\n      <td>247</td>\n      <td>276</td>\n      <td>0.527725</td>\n      <td>0.802326</td>\n    </tr>\n    <tr>\n      <th>1011300</th>\n      <td>39003-ie</td>\n      <td>10.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.633596</td>\n      <td>27195</td>\n      <td>83</td>\n      <td>242</td>\n      <td>281</td>\n      <td>0.537285</td>\n      <td>0.771978</td>\n    </tr>\n    <tr>\n      <th>274755</th>\n      <td>39003-ie</td>\n      <td>36.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>85.431438</td>\n      <td>0.180556</td>\n      <td>26229</td>\n      <td>1049</td>\n      <td>367</td>\n      <td>156</td>\n      <td>0.298279</td>\n      <td>0.129461</td>\n    </tr>\n    <tr>\n      <th>164955</th>\n      <td>39003-ie</td>\n      <td>34.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>85.431438</td>\n      <td>0.180149</td>\n      <td>26215</td>\n      <td>1063</td>\n      <td>366</td>\n      <td>157</td>\n      <td>0.300191</td>\n      <td>0.128689</td>\n    </tr>\n    <tr>\n      <th>274754</th>\n      <td>39003-ie</td>\n      <td>36.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>85.100334</td>\n      <td>0.179840</td>\n      <td>26212</td>\n      <td>1066</td>\n      <td>366</td>\n      <td>157</td>\n      <td>0.300191</td>\n      <td>0.128373</td>\n    </tr>\n    <tr>\n      <th>1032902</th>\n      <td>39003-ie</td>\n      <td>30.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.662207</td>\n      <td>0.173418</td>\n      <td>26358</td>\n      <td>920</td>\n      <td>386</td>\n      <td>137</td>\n      <td>0.261950</td>\n      <td>0.129612</td>\n    </tr>\n    <tr>\n      <th>1044602</th>\n      <td>39003-ie</td>\n      <td>14.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.662207</td>\n      <td>0.173355</td>\n      <td>26094</td>\n      <td>1184</td>\n      <td>361</td>\n      <td>162</td>\n      <td>0.309751</td>\n      <td>0.120357</td>\n    </tr>\n    <tr>\n      <th>976802</th>\n      <td>39003-ie</td>\n      <td>29.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.662207</td>\n      <td>0.173149</td>\n      <td>26345</td>\n      <td>933</td>\n      <td>385</td>\n      <td>138</td>\n      <td>0.263862</td>\n      <td>0.128852</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_id = '39003-ie'\n",
    "tex_table_path = f'../bachelor-thesis/tables/{common_id}/'\n",
    "model_types = prediction_summaries_dict[common_id]['regular']['model_type'].unique()\n",
    "combined_df_lst = []\n",
    "for model_type in model_types:\n",
    "    tmp_df = prediction_summaries_dict[common_id]['regular']\n",
    "    norm_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (tmp_df['normalized'])]\n",
    "    combined_df_lst.append(norm_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "    reg_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (~tmp_df['normalized'])]\n",
    "    combined_df_lst.append(reg_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "combined_df = pd.concat(combined_df_lst).sort_values(by=['f1_score', 'model_type'], ascending=False)\n",
    "combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(\n",
    "    f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n",
    "    label=f'table:{common_id}-top-predictions-summary', index=False,\n",
    "    caption=f'Top predictions summary of {stations_dict[common_id][\"water_name\"]} - {stations_dict[common_id][\"station_name\"]}')\n",
    "combined_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "        common_id  window_size  center_window   model_type  normalized  \\\n276623   39003-ie          5.0           True       median       False   \n276625   39003-ie          5.0           True       median       False   \n276624   39003-ie          5.0           True       median       False   \n913808   39003-ie         34.0           True  mad-z-score        True   \n163808   39003-ie         34.0           True  mad-z-score       False   \n913810   39003-ie         34.0           True  mad-z-score        True   \n163810   39003-ie         34.0           True  mad-z-score       False   \n1017311  39003-ie         32.0           True  mad-z-score        True   \n267311   39003-ie         32.0           True  mad-z-score       False   \n951900   39003-ie         11.0           True       median        True   \n921300   39003-ie         10.0           True       median        True   \n926400   39003-ie          9.0           True       median        True   \n914403   39003-ie         26.0           True      z-score        True   \n164403   39003-ie         26.0           True      z-score       False   \n177346   39003-ie          7.0           True         mean       False   \n177349   39003-ie          7.0           True         mean       False   \n177348   39003-ie          7.0           True         mean       False   \n945903   39003-ie         27.0           True      z-score        True   \n195903   39003-ie         27.0           True      z-score       False   \n954003   39003-ie         25.0           True      z-score        True   \n204003   39003-ie         25.0           True      z-score       False   \n993300   39003-ie          8.0           True         mean        True   \n1035600  39003-ie          9.0           True         mean        True   \n1011300  39003-ie         10.0           True         mean        True   \n274755   39003-ie         36.0           True          mad       False   \n164955   39003-ie         34.0           True          mad       False   \n274754   39003-ie         36.0           True          mad       False   \n1044602  39003-ie         14.0          False          mad        True   \n984602   39003-ie         17.0          False          mad        True   \n1032902  39003-ie         30.0           True          mad        True   \n\n         threshold  f1_score     tn    fp   fn   tp    recall  precision  \n276623    8.615385  0.857143  27198    80   69  447  0.866279   0.848197  \n276625    9.277592  0.856593  27200    78   71  445  0.862403   0.850860  \n276624    8.946488  0.855769  27199    79   71  445  0.862403   0.849237  \n913808    3.648829  0.733514  27093   185  110  406  0.786822   0.686971  \n163808    3.648829  0.733514  27093   185  110  406  0.786822   0.686971  \n913810    4.311037  0.730402  27130   148  134  382  0.740310   0.720755  \n163810    4.311037  0.730402  27130   148  134  382  0.740310   0.720755  \n1017311   4.642140  0.728137  27125   153  133  383  0.742248   0.714552  \n267311    4.642140  0.728137  27125   153  133  383  0.742248   0.714552  \n951900    1.000000  0.720657  27249    29  209  307  0.594961   0.913690  \n921300    1.000000  0.720000  27250    28  210  306  0.593023   0.916168  \n926400    1.000000  0.717026  27259    19  217  299  0.579457   0.940252  \n914403    1.993311  0.682927  27200    78  208  308  0.596899   0.797927  \n164403    1.993311  0.682927  27200    78  208  308  0.596899   0.797927  \n177346   16.230769  0.680352  27119   159  168  348  0.674419   0.686391  \n177349   17.224080  0.679671  27151   127  185  331  0.641473   0.722707  \n177348   16.892977  0.678788  27140   138  180  336  0.651163   0.708861  \n945903    1.993311  0.677668  27193    85  208  308  0.596899   0.783715  \n195903    1.993311  0.677668  27193    85  208  308  0.596899   0.783715  \n954003    1.993311  0.674888  27203    75  215  301  0.583333   0.800532  \n204003    1.993311  0.674888  27203    75  215  301  0.583333   0.800532  \n993300    1.000000  0.642772  27226    52  247  269  0.521318   0.838006  \n1035600   1.000000  0.635514  27210    68  244  272  0.527132   0.800000  \n1011300   1.000000  0.632420  27195    83  239  277  0.536822   0.769444  \n274755   85.431438  0.181290  26229  1049  360  156  0.302326   0.129461  \n164955   85.431438  0.180876  26215  1063  359  157  0.304264   0.128689  \n274754   85.100334  0.180564  26212  1066  359  157  0.304264   0.128373  \n1044602   1.662207  0.167116  26094  1184  361  155  0.300388   0.115758  \n984602    1.662207  0.166486  26098  1180  362  154  0.298450   0.115442  \n1032902   1.662207  0.166028  26358   920  386  130  0.251938   0.123810  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>common_id</th>\n      <th>window_size</th>\n      <th>center_window</th>\n      <th>model_type</th>\n      <th>normalized</th>\n      <th>threshold</th>\n      <th>f1_score</th>\n      <th>tn</th>\n      <th>fp</th>\n      <th>fn</th>\n      <th>tp</th>\n      <th>recall</th>\n      <th>precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>276623</th>\n      <td>39003-ie</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>8.615385</td>\n      <td>0.857143</td>\n      <td>27198</td>\n      <td>80</td>\n      <td>69</td>\n      <td>447</td>\n      <td>0.866279</td>\n      <td>0.848197</td>\n    </tr>\n    <tr>\n      <th>276625</th>\n      <td>39003-ie</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>9.277592</td>\n      <td>0.856593</td>\n      <td>27200</td>\n      <td>78</td>\n      <td>71</td>\n      <td>445</td>\n      <td>0.862403</td>\n      <td>0.850860</td>\n    </tr>\n    <tr>\n      <th>276624</th>\n      <td>39003-ie</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>8.946488</td>\n      <td>0.855769</td>\n      <td>27199</td>\n      <td>79</td>\n      <td>71</td>\n      <td>445</td>\n      <td>0.862403</td>\n      <td>0.849237</td>\n    </tr>\n    <tr>\n      <th>913808</th>\n      <td>39003-ie</td>\n      <td>34.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>3.648829</td>\n      <td>0.733514</td>\n      <td>27093</td>\n      <td>185</td>\n      <td>110</td>\n      <td>406</td>\n      <td>0.786822</td>\n      <td>0.686971</td>\n    </tr>\n    <tr>\n      <th>163808</th>\n      <td>39003-ie</td>\n      <td>34.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>3.648829</td>\n      <td>0.733514</td>\n      <td>27093</td>\n      <td>185</td>\n      <td>110</td>\n      <td>406</td>\n      <td>0.786822</td>\n      <td>0.686971</td>\n    </tr>\n    <tr>\n      <th>913810</th>\n      <td>39003-ie</td>\n      <td>34.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>4.311037</td>\n      <td>0.730402</td>\n      <td>27130</td>\n      <td>148</td>\n      <td>134</td>\n      <td>382</td>\n      <td>0.740310</td>\n      <td>0.720755</td>\n    </tr>\n    <tr>\n      <th>163810</th>\n      <td>39003-ie</td>\n      <td>34.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>4.311037</td>\n      <td>0.730402</td>\n      <td>27130</td>\n      <td>148</td>\n      <td>134</td>\n      <td>382</td>\n      <td>0.740310</td>\n      <td>0.720755</td>\n    </tr>\n    <tr>\n      <th>1017311</th>\n      <td>39003-ie</td>\n      <td>32.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>4.642140</td>\n      <td>0.728137</td>\n      <td>27125</td>\n      <td>153</td>\n      <td>133</td>\n      <td>383</td>\n      <td>0.742248</td>\n      <td>0.714552</td>\n    </tr>\n    <tr>\n      <th>267311</th>\n      <td>39003-ie</td>\n      <td>32.0</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>4.642140</td>\n      <td>0.728137</td>\n      <td>27125</td>\n      <td>153</td>\n      <td>133</td>\n      <td>383</td>\n      <td>0.742248</td>\n      <td>0.714552</td>\n    </tr>\n    <tr>\n      <th>951900</th>\n      <td>39003-ie</td>\n      <td>11.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.720657</td>\n      <td>27249</td>\n      <td>29</td>\n      <td>209</td>\n      <td>307</td>\n      <td>0.594961</td>\n      <td>0.913690</td>\n    </tr>\n    <tr>\n      <th>921300</th>\n      <td>39003-ie</td>\n      <td>10.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.720000</td>\n      <td>27250</td>\n      <td>28</td>\n      <td>210</td>\n      <td>306</td>\n      <td>0.593023</td>\n      <td>0.916168</td>\n    </tr>\n    <tr>\n      <th>926400</th>\n      <td>39003-ie</td>\n      <td>9.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.717026</td>\n      <td>27259</td>\n      <td>19</td>\n      <td>217</td>\n      <td>299</td>\n      <td>0.579457</td>\n      <td>0.940252</td>\n    </tr>\n    <tr>\n      <th>914403</th>\n      <td>39003-ie</td>\n      <td>26.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.682927</td>\n      <td>27200</td>\n      <td>78</td>\n      <td>208</td>\n      <td>308</td>\n      <td>0.596899</td>\n      <td>0.797927</td>\n    </tr>\n    <tr>\n      <th>164403</th>\n      <td>39003-ie</td>\n      <td>26.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>1.993311</td>\n      <td>0.682927</td>\n      <td>27200</td>\n      <td>78</td>\n      <td>208</td>\n      <td>308</td>\n      <td>0.596899</td>\n      <td>0.797927</td>\n    </tr>\n    <tr>\n      <th>177346</th>\n      <td>39003-ie</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>16.230769</td>\n      <td>0.680352</td>\n      <td>27119</td>\n      <td>159</td>\n      <td>168</td>\n      <td>348</td>\n      <td>0.674419</td>\n      <td>0.686391</td>\n    </tr>\n    <tr>\n      <th>177349</th>\n      <td>39003-ie</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>17.224080</td>\n      <td>0.679671</td>\n      <td>27151</td>\n      <td>127</td>\n      <td>185</td>\n      <td>331</td>\n      <td>0.641473</td>\n      <td>0.722707</td>\n    </tr>\n    <tr>\n      <th>177348</th>\n      <td>39003-ie</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>16.892977</td>\n      <td>0.678788</td>\n      <td>27140</td>\n      <td>138</td>\n      <td>180</td>\n      <td>336</td>\n      <td>0.651163</td>\n      <td>0.708861</td>\n    </tr>\n    <tr>\n      <th>945903</th>\n      <td>39003-ie</td>\n      <td>27.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.677668</td>\n      <td>27193</td>\n      <td>85</td>\n      <td>208</td>\n      <td>308</td>\n      <td>0.596899</td>\n      <td>0.783715</td>\n    </tr>\n    <tr>\n      <th>195903</th>\n      <td>39003-ie</td>\n      <td>27.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>1.993311</td>\n      <td>0.677668</td>\n      <td>27193</td>\n      <td>85</td>\n      <td>208</td>\n      <td>308</td>\n      <td>0.596899</td>\n      <td>0.783715</td>\n    </tr>\n    <tr>\n      <th>954003</th>\n      <td>39003-ie</td>\n      <td>25.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>1.993311</td>\n      <td>0.674888</td>\n      <td>27203</td>\n      <td>75</td>\n      <td>215</td>\n      <td>301</td>\n      <td>0.583333</td>\n      <td>0.800532</td>\n    </tr>\n    <tr>\n      <th>204003</th>\n      <td>39003-ie</td>\n      <td>25.0</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>1.993311</td>\n      <td>0.674888</td>\n      <td>27203</td>\n      <td>75</td>\n      <td>215</td>\n      <td>301</td>\n      <td>0.583333</td>\n      <td>0.800532</td>\n    </tr>\n    <tr>\n      <th>993300</th>\n      <td>39003-ie</td>\n      <td>8.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.642772</td>\n      <td>27226</td>\n      <td>52</td>\n      <td>247</td>\n      <td>269</td>\n      <td>0.521318</td>\n      <td>0.838006</td>\n    </tr>\n    <tr>\n      <th>1035600</th>\n      <td>39003-ie</td>\n      <td>9.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.635514</td>\n      <td>27210</td>\n      <td>68</td>\n      <td>244</td>\n      <td>272</td>\n      <td>0.527132</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <th>1011300</th>\n      <td>39003-ie</td>\n      <td>10.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.632420</td>\n      <td>27195</td>\n      <td>83</td>\n      <td>239</td>\n      <td>277</td>\n      <td>0.536822</td>\n      <td>0.769444</td>\n    </tr>\n    <tr>\n      <th>274755</th>\n      <td>39003-ie</td>\n      <td>36.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>85.431438</td>\n      <td>0.181290</td>\n      <td>26229</td>\n      <td>1049</td>\n      <td>360</td>\n      <td>156</td>\n      <td>0.302326</td>\n      <td>0.129461</td>\n    </tr>\n    <tr>\n      <th>164955</th>\n      <td>39003-ie</td>\n      <td>34.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>85.431438</td>\n      <td>0.180876</td>\n      <td>26215</td>\n      <td>1063</td>\n      <td>359</td>\n      <td>157</td>\n      <td>0.304264</td>\n      <td>0.128689</td>\n    </tr>\n    <tr>\n      <th>274754</th>\n      <td>39003-ie</td>\n      <td>36.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>85.100334</td>\n      <td>0.180564</td>\n      <td>26212</td>\n      <td>1066</td>\n      <td>359</td>\n      <td>157</td>\n      <td>0.304264</td>\n      <td>0.128373</td>\n    </tr>\n    <tr>\n      <th>1044602</th>\n      <td>39003-ie</td>\n      <td>14.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.662207</td>\n      <td>0.167116</td>\n      <td>26094</td>\n      <td>1184</td>\n      <td>361</td>\n      <td>155</td>\n      <td>0.300388</td>\n      <td>0.115758</td>\n    </tr>\n    <tr>\n      <th>984602</th>\n      <td>39003-ie</td>\n      <td>17.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.662207</td>\n      <td>0.166486</td>\n      <td>26098</td>\n      <td>1180</td>\n      <td>362</td>\n      <td>154</td>\n      <td>0.298450</td>\n      <td>0.115442</td>\n    </tr>\n    <tr>\n      <th>1032902</th>\n      <td>39003-ie</td>\n      <td>30.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>1.662207</td>\n      <td>0.166028</td>\n      <td>26358</td>\n      <td>920</td>\n      <td>386</td>\n      <td>130</td>\n      <td>0.251938</td>\n      <td>0.123810</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_id = '39003-ie'\n",
    "tex_table_path = f'../bachelor-thesis/tables/{common_id}/'\n",
    "model_types = prediction_summaries_dict[common_id]['preprocessed']['model_type'].unique()\n",
    "combined_df_lst = []\n",
    "for model_type in model_types:\n",
    "    tmp_df = prediction_summaries_dict[common_id]['preprocessed']\n",
    "    norm_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (tmp_df['normalized'])]\n",
    "    combined_df_lst.append(norm_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "    reg_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (~tmp_df['normalized'])]\n",
    "    combined_df_lst.append(reg_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "combined_df = pd.concat(combined_df_lst).sort_values(by=['f1_score', 'model_type'], ascending=False)\n",
    "# combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(\n",
    "#     f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n",
    "#     label=f'table:{common_id}-top-predictions-summary', index=False,\n",
    "#     caption=f'Top predictions summary of {stations_dict[common_id][\"water_name\"]} - {stations_dict[common_id][\"station_name\"]}')\n",
    "combined_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_274729/3358889079.py:12: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n"
     ]
    },
    {
     "data": {
      "text/plain": "           common_id  window_size  center_window   model_type  normalized  \\\n1280405  42960105-de          6.0           True       median        True   \n559873   42960105-de          4.0           True       median       False   \n559877   42960105-de          4.0           True       median       False   \n559876   42960105-de          4.0           True       median       False   \n1209300  42960105-de          3.0           True       median        True   \n1309804  42960105-de          4.0           True       median        True   \n1346715  42960105-de         19.0           True         mean        True   \n1296014  42960105-de         17.0           True         mean        True   \n1331113  42960105-de         15.0           True         mean        True   \n581286   42960105-de         15.0           True         mean       False   \n555486   42960105-de         16.0           True         mean       False   \n555477   42960105-de         16.0           True         mean       False   \n1217425  42960105-de          2.0          False          mad        True   \n1309525  42960105-de          2.0           True          mad        True   \n1217427  42960105-de          2.0          False          mad        True   \n1206354  42960105-de          NaN           True      z-score        True   \n1206350  42960105-de          NaN           True      z-score        True   \n1248048  42960105-de          NaN          False      z-score        True   \n498056   42960105-de          NaN          False      z-score       False   \n498047   42960105-de          NaN          False      z-score       False   \n498045   42960105-de          NaN          False      z-score       False   \n1338695  42960105-de          NaN           True  mad-z-score        True   \n1338693  42960105-de          NaN           True  mad-z-score        True   \n1338686  42960105-de          NaN           True  mad-z-score        True   \n588695   42960105-de          NaN           True  mad-z-score       False   \n588693   42960105-de          NaN           True  mad-z-score       False   \n588686   42960105-de          NaN           True  mad-z-score       False   \n469199   42960105-de          NaN           True          mad       False   \n497099   42960105-de          NaN          False          mad       False   \n469198   42960105-de          NaN           True          mad       False   \n\n          threshold  f1_score     tn    fp  fn  tp  recall  precision  \n1280405    2.655518  0.731707  50990     1  10  15    0.60   0.937500  \n559873    25.170569  0.731707  50990     1  10  15    0.60   0.937500  \n559877    26.494983  0.731707  50990     1  10  15    0.60   0.937500  \n559876    26.163880  0.731707  50990     1  10  15    0.60   0.937500  \n1209300    1.000000  0.720000  50984     7   7  18    0.72   0.720000  \n1309804    2.324415  0.714286  50989     2  10  15    0.60   0.882353  \n1346715    5.966555  0.571429  50991     0  15  10    0.40   1.000000  \n1296014    5.635452  0.571429  50991     0  15  10    0.40   1.000000  \n1331113    5.304348  0.571429  50991     0  15  10    0.40   1.000000  \n581286    62.585284  0.571429  50991     0  15  10    0.40   1.000000  \n555486    62.585284  0.571429  50991     0  15  10    0.40   1.000000  \n555477    59.605351  0.571429  50991     0  15  10    0.40   1.000000  \n1217425    9.277592  0.454545  50982     9  15  10    0.40   0.526316  \n1309525    9.277592  0.454545  50982     9  15  10    0.40   0.526316  \n1217427    9.939799  0.439024  50984     7  16   9    0.36   0.562500  \n1206354   18.879599  0.275862  50991     0  21   4    0.16   1.000000  \n1206350   17.555184  0.275862  50991     0  21   4    0.16   1.000000  \n1248048   16.892977  0.275862  50991     0  21   4    0.16   1.000000  \n498056    19.541806  0.275862  50991     0  21   4    0.16   1.000000  \n498047    16.561873  0.275862  50991     0  21   4    0.16   1.000000  \n498045    15.899666  0.275862  50991     0  21   4    0.16   1.000000  \n1338695   32.454849  0.275862  50991     0  21   4    0.16   1.000000  \n1338693   31.792642  0.275862  50991     0  21   4    0.16   1.000000  \n1338686   29.474916  0.275862  50991     0  21   4    0.16   1.000000  \n588695    32.454849  0.275862  50991     0  21   4    0.16   1.000000  \n588693    31.792642  0.275862  50991     0  21   4    0.16   1.000000  \n588686    29.474916  0.275862  50991     0  21   4    0.16   1.000000  \n469199   100.000000  0.005068  45112  5879  10  15    0.60   0.002545  \n497099   100.000000  0.005068  45112  5879  10  15    0.60   0.002545  \n469198    99.668896  0.004548  44435  6556  10  15    0.60   0.002283  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>common_id</th>\n      <th>window_size</th>\n      <th>center_window</th>\n      <th>model_type</th>\n      <th>normalized</th>\n      <th>threshold</th>\n      <th>f1_score</th>\n      <th>tn</th>\n      <th>fp</th>\n      <th>fn</th>\n      <th>tp</th>\n      <th>recall</th>\n      <th>precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1280405</th>\n      <td>42960105-de</td>\n      <td>6.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>2.655518</td>\n      <td>0.731707</td>\n      <td>50990</td>\n      <td>1</td>\n      <td>10</td>\n      <td>15</td>\n      <td>0.60</td>\n      <td>0.937500</td>\n    </tr>\n    <tr>\n      <th>559873</th>\n      <td>42960105-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>25.170569</td>\n      <td>0.731707</td>\n      <td>50990</td>\n      <td>1</td>\n      <td>10</td>\n      <td>15</td>\n      <td>0.60</td>\n      <td>0.937500</td>\n    </tr>\n    <tr>\n      <th>559877</th>\n      <td>42960105-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>26.494983</td>\n      <td>0.731707</td>\n      <td>50990</td>\n      <td>1</td>\n      <td>10</td>\n      <td>15</td>\n      <td>0.60</td>\n      <td>0.937500</td>\n    </tr>\n    <tr>\n      <th>559876</th>\n      <td>42960105-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>26.163880</td>\n      <td>0.731707</td>\n      <td>50990</td>\n      <td>1</td>\n      <td>10</td>\n      <td>15</td>\n      <td>0.60</td>\n      <td>0.937500</td>\n    </tr>\n    <tr>\n      <th>1209300</th>\n      <td>42960105-de</td>\n      <td>3.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>1.000000</td>\n      <td>0.720000</td>\n      <td>50984</td>\n      <td>7</td>\n      <td>7</td>\n      <td>18</td>\n      <td>0.72</td>\n      <td>0.720000</td>\n    </tr>\n    <tr>\n      <th>1309804</th>\n      <td>42960105-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>2.324415</td>\n      <td>0.714286</td>\n      <td>50989</td>\n      <td>2</td>\n      <td>10</td>\n      <td>15</td>\n      <td>0.60</td>\n      <td>0.882353</td>\n    </tr>\n    <tr>\n      <th>1346715</th>\n      <td>42960105-de</td>\n      <td>19.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>5.966555</td>\n      <td>0.571429</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>15</td>\n      <td>10</td>\n      <td>0.40</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1296014</th>\n      <td>42960105-de</td>\n      <td>17.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>5.635452</td>\n      <td>0.571429</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>15</td>\n      <td>10</td>\n      <td>0.40</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1331113</th>\n      <td>42960105-de</td>\n      <td>15.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>5.304348</td>\n      <td>0.571429</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>15</td>\n      <td>10</td>\n      <td>0.40</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>581286</th>\n      <td>42960105-de</td>\n      <td>15.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>62.585284</td>\n      <td>0.571429</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>15</td>\n      <td>10</td>\n      <td>0.40</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>555486</th>\n      <td>42960105-de</td>\n      <td>16.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>62.585284</td>\n      <td>0.571429</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>15</td>\n      <td>10</td>\n      <td>0.40</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>555477</th>\n      <td>42960105-de</td>\n      <td>16.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>59.605351</td>\n      <td>0.571429</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>15</td>\n      <td>10</td>\n      <td>0.40</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1217425</th>\n      <td>42960105-de</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>9.277592</td>\n      <td>0.454545</td>\n      <td>50982</td>\n      <td>9</td>\n      <td>15</td>\n      <td>10</td>\n      <td>0.40</td>\n      <td>0.526316</td>\n    </tr>\n    <tr>\n      <th>1309525</th>\n      <td>42960105-de</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>9.277592</td>\n      <td>0.454545</td>\n      <td>50982</td>\n      <td>9</td>\n      <td>15</td>\n      <td>10</td>\n      <td>0.40</td>\n      <td>0.526316</td>\n    </tr>\n    <tr>\n      <th>1217427</th>\n      <td>42960105-de</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>9.939799</td>\n      <td>0.439024</td>\n      <td>50984</td>\n      <td>7</td>\n      <td>16</td>\n      <td>9</td>\n      <td>0.36</td>\n      <td>0.562500</td>\n    </tr>\n    <tr>\n      <th>1206354</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>18.879599</td>\n      <td>0.275862</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>21</td>\n      <td>4</td>\n      <td>0.16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1206350</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>17.555184</td>\n      <td>0.275862</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>21</td>\n      <td>4</td>\n      <td>0.16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1248048</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>16.892977</td>\n      <td>0.275862</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>21</td>\n      <td>4</td>\n      <td>0.16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>498056</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>19.541806</td>\n      <td>0.275862</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>21</td>\n      <td>4</td>\n      <td>0.16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>498047</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>16.561873</td>\n      <td>0.275862</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>21</td>\n      <td>4</td>\n      <td>0.16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>498045</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>15.899666</td>\n      <td>0.275862</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>21</td>\n      <td>4</td>\n      <td>0.16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1338695</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>32.454849</td>\n      <td>0.275862</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>21</td>\n      <td>4</td>\n      <td>0.16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1338693</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>31.792642</td>\n      <td>0.275862</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>21</td>\n      <td>4</td>\n      <td>0.16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1338686</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>29.474916</td>\n      <td>0.275862</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>21</td>\n      <td>4</td>\n      <td>0.16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>588695</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>32.454849</td>\n      <td>0.275862</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>21</td>\n      <td>4</td>\n      <td>0.16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>588693</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>31.792642</td>\n      <td>0.275862</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>21</td>\n      <td>4</td>\n      <td>0.16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>588686</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>29.474916</td>\n      <td>0.275862</td>\n      <td>50991</td>\n      <td>0</td>\n      <td>21</td>\n      <td>4</td>\n      <td>0.16</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>469199</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>100.000000</td>\n      <td>0.005068</td>\n      <td>45112</td>\n      <td>5879</td>\n      <td>10</td>\n      <td>15</td>\n      <td>0.60</td>\n      <td>0.002545</td>\n    </tr>\n    <tr>\n      <th>497099</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>100.000000</td>\n      <td>0.005068</td>\n      <td>45112</td>\n      <td>5879</td>\n      <td>10</td>\n      <td>15</td>\n      <td>0.60</td>\n      <td>0.002545</td>\n    </tr>\n    <tr>\n      <th>469198</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>99.668896</td>\n      <td>0.004548</td>\n      <td>44435</td>\n      <td>6556</td>\n      <td>10</td>\n      <td>15</td>\n      <td>0.60</td>\n      <td>0.002283</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_id = '42960105-de'\n",
    "tex_table_path = f'../bachelor-thesis/tables/{common_id}/'\n",
    "model_types = prediction_summaries_dict[common_id]['regular']['model_type'].unique()\n",
    "combined_df_lst = []\n",
    "for model_type in model_types:\n",
    "    tmp_df = prediction_summaries_dict[common_id]['regular']\n",
    "    norm_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (tmp_df['normalized'])]\n",
    "    combined_df_lst.append(norm_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "    reg_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (~tmp_df['normalized'])]\n",
    "    combined_df_lst.append(reg_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "combined_df = pd.concat(combined_df_lst).sort_values(by=['f1_score', 'model_type'], ascending=False)\n",
    "combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(\n",
    "    f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n",
    "    label=f'table:{common_id}-top-predictions-summary', index=False,\n",
    "    caption=f'Top predictions summary of {stations_dict[common_id][\"water_name\"]} - {stations_dict[common_id][\"station_name\"]}')\n",
    "combined_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "           common_id  window_size  center_window   model_type  normalized  \\\n1309805  42960105-de          4.0           True       median        True   \n1280406  42960105-de          6.0           True       median        True   \n530482   42960105-de          6.0           True       median       False   \n530481   42960105-de          6.0           True       median       False   \n559877   42960105-de          4.0           True       median       False   \n1280404  42960105-de          6.0           True       median        True   \n597372   42960105-de          6.0           True         mean       False   \n1219804  42960105-de          5.0           True         mean        True   \n515468   42960105-de          4.0           True         mean       False   \n515469   42960105-de          4.0           True         mean       False   \n1227305  42960105-de          7.0           True         mean        True   \n1347305  42960105-de          6.0           True         mean        True   \n1309528  42960105-de          2.0           True          mad        True   \n1217428  42960105-de          2.0          False          mad        True   \n1217430  42960105-de          2.0          False          mad        True   \n1338637  42960105-de          NaN           True  mad-z-score        True   \n1252837  42960105-de          NaN          False  mad-z-score        True   \n588637   42960105-de          NaN           True  mad-z-score       False   \n502837   42960105-de          NaN          False  mad-z-score       False   \n1252831  42960105-de          NaN          False  mad-z-score        True   \n502831   42960105-de          NaN          False  mad-z-score       False   \n529217   42960105-de         48.0          False      z-score       False   \n1212917  42960105-de         49.0          False      z-score        True   \n462917   42960105-de         49.0          False      z-score       False   \n1279217  42960105-de         48.0          False      z-score        True   \n1275917  42960105-de         50.0          False      z-score        True   \n525917   42960105-de         50.0          False      z-score       False   \n469199   42960105-de          NaN           True          mad       False   \n497099   42960105-de          NaN          False          mad       False   \n469197   42960105-de          NaN           True          mad       False   \n\n          threshold  f1_score     tn    fp  fn  tp    recall  precision  \n1309805    2.655518  0.666667  50990     1  10  11  0.523810   0.916667  \n1280406    2.986622  0.666667  50990     1  10  11  0.523810   0.916667  \n530482    28.150502  0.666667  50990     1  10  11  0.523810   0.916667  \n530481    27.819398  0.666667  50990     1  10  11  0.523810   0.916667  \n559877    26.494983  0.666667  50990     1  10  11  0.523810   0.916667  \n1280404    2.324415  0.650000  50985     6   8  13  0.619048   0.684211  \n597372    24.839465  0.615385  50985     6   9  12  0.571429   0.666667  \n1219804    2.324415  0.611111  50987     4  10  11  0.523810   0.733333  \n515468    23.515050  0.611111  50987     4  10  11  0.523810   0.733333  \n515469    23.846154  0.611111  50987     4  10  11  0.523810   0.733333  \n1227305    2.655518  0.600000  50984     7   9  12  0.571429   0.631579  \n1347305    2.655518  0.594595  50986     5  10  11  0.523810   0.687500  \n1309528   10.270903  0.352941  50984     7  15   6  0.285714   0.461538  \n1217428   10.270903  0.352941  50984     7  15   6  0.285714   0.461538  \n1217430   10.933110  0.322581  50986     5  16   5  0.238095   0.500000  \n1338637   13.250836  0.121212  50950    41  17   4  0.190476   0.088889  \n1252837   13.250836  0.121212  50950    41  17   4  0.190476   0.088889  \n588637    13.250836  0.121212  50950    41  17   4  0.190476   0.088889  \n502837    13.250836  0.121212  50950    41  17   4  0.190476   0.088889  \n1252831   11.264214  0.113208  50912    79  15   6  0.285714   0.070588  \n502831    11.264214  0.113208  50912    79  15   6  0.285714   0.070588  \n529217     6.628763  0.086957  50968    23  19   2  0.095238   0.080000  \n1212917    6.628763  0.085106  50967    24  19   2  0.095238   0.076923  \n462917     6.628763  0.085106  50967    24  19   2  0.095238   0.076923  \n1279217    6.628763  0.083333  50966    25  19   2  0.095238   0.074074  \n1275917    6.628763  0.076923  50962    29  19   2  0.095238   0.064516  \n525917     6.628763  0.076923  50962    29  19   2  0.095238   0.064516  \n469199   100.000000  0.003722  45112  5879  10  11  0.523810   0.001868  \n497099   100.000000  0.003722  45112  5879  10  11  0.523810   0.001868  \n469197    99.337793  0.003339  44435  6556  10  11  0.523810   0.001675  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>common_id</th>\n      <th>window_size</th>\n      <th>center_window</th>\n      <th>model_type</th>\n      <th>normalized</th>\n      <th>threshold</th>\n      <th>f1_score</th>\n      <th>tn</th>\n      <th>fp</th>\n      <th>fn</th>\n      <th>tp</th>\n      <th>recall</th>\n      <th>precision</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1309805</th>\n      <td>42960105-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>2.655518</td>\n      <td>0.666667</td>\n      <td>50990</td>\n      <td>1</td>\n      <td>10</td>\n      <td>11</td>\n      <td>0.523810</td>\n      <td>0.916667</td>\n    </tr>\n    <tr>\n      <th>1280406</th>\n      <td>42960105-de</td>\n      <td>6.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>2.986622</td>\n      <td>0.666667</td>\n      <td>50990</td>\n      <td>1</td>\n      <td>10</td>\n      <td>11</td>\n      <td>0.523810</td>\n      <td>0.916667</td>\n    </tr>\n    <tr>\n      <th>530482</th>\n      <td>42960105-de</td>\n      <td>6.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>28.150502</td>\n      <td>0.666667</td>\n      <td>50990</td>\n      <td>1</td>\n      <td>10</td>\n      <td>11</td>\n      <td>0.523810</td>\n      <td>0.916667</td>\n    </tr>\n    <tr>\n      <th>530481</th>\n      <td>42960105-de</td>\n      <td>6.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>27.819398</td>\n      <td>0.666667</td>\n      <td>50990</td>\n      <td>1</td>\n      <td>10</td>\n      <td>11</td>\n      <td>0.523810</td>\n      <td>0.916667</td>\n    </tr>\n    <tr>\n      <th>559877</th>\n      <td>42960105-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>False</td>\n      <td>26.494983</td>\n      <td>0.666667</td>\n      <td>50990</td>\n      <td>1</td>\n      <td>10</td>\n      <td>11</td>\n      <td>0.523810</td>\n      <td>0.916667</td>\n    </tr>\n    <tr>\n      <th>1280404</th>\n      <td>42960105-de</td>\n      <td>6.0</td>\n      <td>True</td>\n      <td>median</td>\n      <td>True</td>\n      <td>2.324415</td>\n      <td>0.650000</td>\n      <td>50985</td>\n      <td>6</td>\n      <td>8</td>\n      <td>13</td>\n      <td>0.619048</td>\n      <td>0.684211</td>\n    </tr>\n    <tr>\n      <th>597372</th>\n      <td>42960105-de</td>\n      <td>6.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>24.839465</td>\n      <td>0.615385</td>\n      <td>50985</td>\n      <td>6</td>\n      <td>9</td>\n      <td>12</td>\n      <td>0.571429</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>1219804</th>\n      <td>42960105-de</td>\n      <td>5.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>2.324415</td>\n      <td>0.611111</td>\n      <td>50987</td>\n      <td>4</td>\n      <td>10</td>\n      <td>11</td>\n      <td>0.523810</td>\n      <td>0.733333</td>\n    </tr>\n    <tr>\n      <th>515468</th>\n      <td>42960105-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>23.515050</td>\n      <td>0.611111</td>\n      <td>50987</td>\n      <td>4</td>\n      <td>10</td>\n      <td>11</td>\n      <td>0.523810</td>\n      <td>0.733333</td>\n    </tr>\n    <tr>\n      <th>515469</th>\n      <td>42960105-de</td>\n      <td>4.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>False</td>\n      <td>23.846154</td>\n      <td>0.611111</td>\n      <td>50987</td>\n      <td>4</td>\n      <td>10</td>\n      <td>11</td>\n      <td>0.523810</td>\n      <td>0.733333</td>\n    </tr>\n    <tr>\n      <th>1227305</th>\n      <td>42960105-de</td>\n      <td>7.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>2.655518</td>\n      <td>0.600000</td>\n      <td>50984</td>\n      <td>7</td>\n      <td>9</td>\n      <td>12</td>\n      <td>0.571429</td>\n      <td>0.631579</td>\n    </tr>\n    <tr>\n      <th>1347305</th>\n      <td>42960105-de</td>\n      <td>6.0</td>\n      <td>True</td>\n      <td>mean</td>\n      <td>True</td>\n      <td>2.655518</td>\n      <td>0.594595</td>\n      <td>50986</td>\n      <td>5</td>\n      <td>10</td>\n      <td>11</td>\n      <td>0.523810</td>\n      <td>0.687500</td>\n    </tr>\n    <tr>\n      <th>1309528</th>\n      <td>42960105-de</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>10.270903</td>\n      <td>0.352941</td>\n      <td>50984</td>\n      <td>7</td>\n      <td>15</td>\n      <td>6</td>\n      <td>0.285714</td>\n      <td>0.461538</td>\n    </tr>\n    <tr>\n      <th>1217428</th>\n      <td>42960105-de</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>10.270903</td>\n      <td>0.352941</td>\n      <td>50984</td>\n      <td>7</td>\n      <td>15</td>\n      <td>6</td>\n      <td>0.285714</td>\n      <td>0.461538</td>\n    </tr>\n    <tr>\n      <th>1217430</th>\n      <td>42960105-de</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>True</td>\n      <td>10.933110</td>\n      <td>0.322581</td>\n      <td>50986</td>\n      <td>5</td>\n      <td>16</td>\n      <td>5</td>\n      <td>0.238095</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>1338637</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>13.250836</td>\n      <td>0.121212</td>\n      <td>50950</td>\n      <td>41</td>\n      <td>17</td>\n      <td>4</td>\n      <td>0.190476</td>\n      <td>0.088889</td>\n    </tr>\n    <tr>\n      <th>1252837</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>13.250836</td>\n      <td>0.121212</td>\n      <td>50950</td>\n      <td>41</td>\n      <td>17</td>\n      <td>4</td>\n      <td>0.190476</td>\n      <td>0.088889</td>\n    </tr>\n    <tr>\n      <th>588637</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>13.250836</td>\n      <td>0.121212</td>\n      <td>50950</td>\n      <td>41</td>\n      <td>17</td>\n      <td>4</td>\n      <td>0.190476</td>\n      <td>0.088889</td>\n    </tr>\n    <tr>\n      <th>502837</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>13.250836</td>\n      <td>0.121212</td>\n      <td>50950</td>\n      <td>41</td>\n      <td>17</td>\n      <td>4</td>\n      <td>0.190476</td>\n      <td>0.088889</td>\n    </tr>\n    <tr>\n      <th>1252831</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>mad-z-score</td>\n      <td>True</td>\n      <td>11.264214</td>\n      <td>0.113208</td>\n      <td>50912</td>\n      <td>79</td>\n      <td>15</td>\n      <td>6</td>\n      <td>0.285714</td>\n      <td>0.070588</td>\n    </tr>\n    <tr>\n      <th>502831</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>mad-z-score</td>\n      <td>False</td>\n      <td>11.264214</td>\n      <td>0.113208</td>\n      <td>50912</td>\n      <td>79</td>\n      <td>15</td>\n      <td>6</td>\n      <td>0.285714</td>\n      <td>0.070588</td>\n    </tr>\n    <tr>\n      <th>529217</th>\n      <td>42960105-de</td>\n      <td>48.0</td>\n      <td>False</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>6.628763</td>\n      <td>0.086957</td>\n      <td>50968</td>\n      <td>23</td>\n      <td>19</td>\n      <td>2</td>\n      <td>0.095238</td>\n      <td>0.080000</td>\n    </tr>\n    <tr>\n      <th>1212917</th>\n      <td>42960105-de</td>\n      <td>49.0</td>\n      <td>False</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>6.628763</td>\n      <td>0.085106</td>\n      <td>50967</td>\n      <td>24</td>\n      <td>19</td>\n      <td>2</td>\n      <td>0.095238</td>\n      <td>0.076923</td>\n    </tr>\n    <tr>\n      <th>462917</th>\n      <td>42960105-de</td>\n      <td>49.0</td>\n      <td>False</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>6.628763</td>\n      <td>0.085106</td>\n      <td>50967</td>\n      <td>24</td>\n      <td>19</td>\n      <td>2</td>\n      <td>0.095238</td>\n      <td>0.076923</td>\n    </tr>\n    <tr>\n      <th>1279217</th>\n      <td>42960105-de</td>\n      <td>48.0</td>\n      <td>False</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>6.628763</td>\n      <td>0.083333</td>\n      <td>50966</td>\n      <td>25</td>\n      <td>19</td>\n      <td>2</td>\n      <td>0.095238</td>\n      <td>0.074074</td>\n    </tr>\n    <tr>\n      <th>1275917</th>\n      <td>42960105-de</td>\n      <td>50.0</td>\n      <td>False</td>\n      <td>z-score</td>\n      <td>True</td>\n      <td>6.628763</td>\n      <td>0.076923</td>\n      <td>50962</td>\n      <td>29</td>\n      <td>19</td>\n      <td>2</td>\n      <td>0.095238</td>\n      <td>0.064516</td>\n    </tr>\n    <tr>\n      <th>525917</th>\n      <td>42960105-de</td>\n      <td>50.0</td>\n      <td>False</td>\n      <td>z-score</td>\n      <td>False</td>\n      <td>6.628763</td>\n      <td>0.076923</td>\n      <td>50962</td>\n      <td>29</td>\n      <td>19</td>\n      <td>2</td>\n      <td>0.095238</td>\n      <td>0.064516</td>\n    </tr>\n    <tr>\n      <th>469199</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>100.000000</td>\n      <td>0.003722</td>\n      <td>45112</td>\n      <td>5879</td>\n      <td>10</td>\n      <td>11</td>\n      <td>0.523810</td>\n      <td>0.001868</td>\n    </tr>\n    <tr>\n      <th>497099</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>100.000000</td>\n      <td>0.003722</td>\n      <td>45112</td>\n      <td>5879</td>\n      <td>10</td>\n      <td>11</td>\n      <td>0.523810</td>\n      <td>0.001868</td>\n    </tr>\n    <tr>\n      <th>469197</th>\n      <td>42960105-de</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>mad</td>\n      <td>False</td>\n      <td>99.337793</td>\n      <td>0.003339</td>\n      <td>44435</td>\n      <td>6556</td>\n      <td>10</td>\n      <td>11</td>\n      <td>0.523810</td>\n      <td>0.001675</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_id = '42960105-de'\n",
    "tex_table_path = f'../bachelor-thesis/tables/{common_id}/'\n",
    "model_types = prediction_summaries_dict[common_id]['preprocessed']['model_type'].unique()\n",
    "combined_df_lst = []\n",
    "for model_type in model_types:\n",
    "    tmp_df = prediction_summaries_dict[common_id]['preprocessed']\n",
    "    norm_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (tmp_df['normalized'])]\n",
    "    combined_df_lst.append(norm_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "    reg_df = tmp_df.loc[(tmp_df['model_type'] == model_type) & (~tmp_df['normalized'])]\n",
    "    combined_df_lst.append(reg_df.sort_values(by=['f1_score'], ascending=False).head(3))\n",
    "combined_df = pd.concat(combined_df_lst).sort_values(by=['f1_score', 'model_type'], ascending=False)\n",
    "# combined_df[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score']].to_latex(\n",
    "#     f'{tex_table_path}/{common_id}-top-predictions-summary.tex', position='htp',\n",
    "#     label=f'table:{common_id}-top-predictions-summary', index=False,\n",
    "#     caption=f'Top predictions summary of {stations_dict[common_id][\"water_name\"]} - {stations_dict[common_id][\"station_name\"]}')\n",
    "combined_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_274729/2816121516.py:31: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  combined_df.sort_values(by=['average_f1_score'], ascending=False).head(5)[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'average_f1_score']].to_latex(\n"
     ]
    },
    {
     "data": {
      "text/plain": "      window_size  center_window  normalized  threshold model_type  \\\n9317          3.0           True       False   6.628763     median   \n9318          3.0           True       False   6.959866     median   \n9316          3.0           True       False   6.297659     median   \n9322          3.0           True       False   8.284281     median   \n9323          3.0           True       False   8.615385     median   \n\n      2386-ch-f1_score  2386-ch-tn  2386-ch-fp  2386-ch-fn  2386-ch-tp  ...  \\\n9317          0.639175       50444          23          47          62  ...   \n9318          0.635417       50445          22          48          61  ...   \n9316          0.629442       50441          26          47          62  ...   \n9322          0.490323       50459           8          71          38  ...   \n9323          0.490323       50459           8          71          38  ...   \n\n      39003-ie-recall  42960105-de-f1_score  42960105-de-tn  42960105-de-fp  \\\n9317         0.780115              0.625000           50972              19   \n9318         0.780115              0.625000           50972              19   \n9316         0.782027              0.625000           50972              19   \n9322         0.768642              0.678571           50979              12   \n9323         0.768642              0.678571           50979              12   \n\n      42960105-de-fn  42960105-de-tp  42960105-de-precision  \\\n9317               5              20               0.512821   \n9318               5              20               0.512821   \n9316               5              20               0.512821   \n9322               6              19               0.612903   \n9323               6              19               0.612903   \n\n      42960105-de-recall  average_f1_score  harmonic_mean_f1_score  \n9317                0.80          0.725722                0.715504  \n9318                0.80          0.725293                0.714808  \n9316                0.80          0.723374                0.712691  \n9322                0.76          0.719480                0.689293  \n9323                0.76          0.719397                0.689112  \n\n[5 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>window_size</th>\n      <th>center_window</th>\n      <th>normalized</th>\n      <th>threshold</th>\n      <th>model_type</th>\n      <th>2386-ch-f1_score</th>\n      <th>2386-ch-tn</th>\n      <th>2386-ch-fp</th>\n      <th>2386-ch-fn</th>\n      <th>2386-ch-tp</th>\n      <th>...</th>\n      <th>39003-ie-recall</th>\n      <th>42960105-de-f1_score</th>\n      <th>42960105-de-tn</th>\n      <th>42960105-de-fp</th>\n      <th>42960105-de-fn</th>\n      <th>42960105-de-tp</th>\n      <th>42960105-de-precision</th>\n      <th>42960105-de-recall</th>\n      <th>average_f1_score</th>\n      <th>harmonic_mean_f1_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9317</th>\n      <td>3.0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>6.628763</td>\n      <td>median</td>\n      <td>0.639175</td>\n      <td>50444</td>\n      <td>23</td>\n      <td>47</td>\n      <td>62</td>\n      <td>...</td>\n      <td>0.780115</td>\n      <td>0.625000</td>\n      <td>50972</td>\n      <td>19</td>\n      <td>5</td>\n      <td>20</td>\n      <td>0.512821</td>\n      <td>0.80</td>\n      <td>0.725722</td>\n      <td>0.715504</td>\n    </tr>\n    <tr>\n      <th>9318</th>\n      <td>3.0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>6.959866</td>\n      <td>median</td>\n      <td>0.635417</td>\n      <td>50445</td>\n      <td>22</td>\n      <td>48</td>\n      <td>61</td>\n      <td>...</td>\n      <td>0.780115</td>\n      <td>0.625000</td>\n      <td>50972</td>\n      <td>19</td>\n      <td>5</td>\n      <td>20</td>\n      <td>0.512821</td>\n      <td>0.80</td>\n      <td>0.725293</td>\n      <td>0.714808</td>\n    </tr>\n    <tr>\n      <th>9316</th>\n      <td>3.0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>6.297659</td>\n      <td>median</td>\n      <td>0.629442</td>\n      <td>50441</td>\n      <td>26</td>\n      <td>47</td>\n      <td>62</td>\n      <td>...</td>\n      <td>0.782027</td>\n      <td>0.625000</td>\n      <td>50972</td>\n      <td>19</td>\n      <td>5</td>\n      <td>20</td>\n      <td>0.512821</td>\n      <td>0.80</td>\n      <td>0.723374</td>\n      <td>0.712691</td>\n    </tr>\n    <tr>\n      <th>9322</th>\n      <td>3.0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>8.284281</td>\n      <td>median</td>\n      <td>0.490323</td>\n      <td>50459</td>\n      <td>8</td>\n      <td>71</td>\n      <td>38</td>\n      <td>...</td>\n      <td>0.768642</td>\n      <td>0.678571</td>\n      <td>50979</td>\n      <td>12</td>\n      <td>6</td>\n      <td>19</td>\n      <td>0.612903</td>\n      <td>0.76</td>\n      <td>0.719480</td>\n      <td>0.689293</td>\n    </tr>\n    <tr>\n      <th>9323</th>\n      <td>3.0</td>\n      <td>True</td>\n      <td>False</td>\n      <td>8.615385</td>\n      <td>median</td>\n      <td>0.490323</td>\n      <td>50459</td>\n      <td>8</td>\n      <td>71</td>\n      <td>38</td>\n      <td>...</td>\n      <td>0.768642</td>\n      <td>0.678571</td>\n      <td>50979</td>\n      <td>12</td>\n      <td>6</td>\n      <td>19</td>\n      <td>0.612903</td>\n      <td>0.76</td>\n      <td>0.719397</td>\n      <td>0.689112</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows  42 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe with overall best parameters\n",
    "combined_df = None\n",
    "tex_table_path = f'../bachelor-thesis/tables/'\n",
    "for common_id in prediction_summaries_dict.keys():\n",
    "    if combined_df is None:\n",
    "        combined_df = prediction_summaries_dict[common_id]['regular'][\n",
    "            ['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'f1_score', 'tn', 'fp', 'fn',\n",
    "             'tp', 'precision', 'recall']].rename(columns={'f1_score': f'{common_id}-f1_score', 'tn': f'{common_id}-tn',\n",
    "                                                           'fp': f'{common_id}-fp', 'fn': f'{common_id}-fn',\n",
    "                                                           'tp': f'{common_id}-tp',\n",
    "                                                           'precision': f'{common_id}-precision',\n",
    "                                                           'recall': f'{common_id}-recall'})\n",
    "    else:\n",
    "        combined_df = combined_df.merge(prediction_summaries_dict[common_id]['regular'][\n",
    "            ['window_size', 'center_window', 'normalized', 'threshold', 'model_type',\n",
    "             'f1_score', 'tn', 'fp', 'fn', 'tp', 'precision', 'recall']].rename(\n",
    "            columns={'f1_score': f'{common_id}-f1_score', 'tn': f'{common_id}-tn',\n",
    "                     'fp': f'{common_id}-fp', 'fn': f'{common_id}-fn',\n",
    "                     'tp': f'{common_id}-tp', 'precision': f'{common_id}-precision',\n",
    "                     'recall': f'{common_id}-recall'}),\n",
    "            on=['window_size', 'center_window', 'normalized', 'threshold', 'model_type'],\n",
    "            how='outer')\n",
    "    # break\n",
    "combined_df['average_f1_score'] = (combined_df['2386-ch-f1_score'] + combined_df['2720050000-de-f1_score'] +\n",
    "                                   combined_df['36022-ie-f1_score'] + combined_df['39003-ie-f1_score'] + combined_df[\n",
    "                                       '42960105-de-f1_score']) / 5\n",
    "combined_df['harmonic_mean_f1_score'] = 5 / (1/combined_df['2386-ch-f1_score'] + 1/combined_df['2720050000-de-f1_score'] +\n",
    "                                   1/combined_df['36022-ie-f1_score'] + 1/combined_df['39003-ie-f1_score'] + 1/combined_df[\n",
    "                                       '42960105-de-f1_score'])\n",
    "\n",
    "combined_df.sort_values(by=['average_f1_score'], ascending=False).head(5)[['window_size', 'center_window', 'normalized', 'threshold', 'model_type', 'average_f1_score']].to_latex(\n",
    "    f'{tex_table_path}/top-avg-predictions-summary.tex', position='htp',\n",
    "    label=f'table:top-avg-predictions-summary', index=False,\n",
    "    caption=f'Best parameters of the average F1-score of all stations tested')\n",
    "combined_df.sort_values(by=['average_f1_score'], ascending=False).head(5)\n",
    "# combined_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# for common_id in ['36022-ie']:\n",
    "# for common_id in prediction_summaries_dict.keys():\n",
    "#     display('regular')\n",
    "#     display(prediction_summaries_dict[common_id]['regular'].sort_values(by=['f1_score'], ascending=False).head(5))\n",
    "# for model_type in prediction_summary_df['model_type'].unique():\n",
    "\n",
    "# tmp_df = prediction_summaries_dict[common_id]['regular']\n",
    "# tmp_df = tmp_df.loc[tmp_df['model_type'] == model_type]\n",
    "# display('regular')\n",
    "# display(tmp_df.sort_values(by=['f1_score'], ascending=False).head(5))\n",
    "# tmp_df = prediction_summaries_dict[common_id]['preprocessed']\n",
    "# tmp_df = tmp_df.loc[tmp_df['model_type'] == model_type]\n",
    "# display('preprocessed')\n",
    "# display(tmp_df.sort_values(by=['f1_score'], ascending=False).head(10))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 49511 entries, 0 to 49521\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype              \n",
      "---  ------       --------------  -----              \n",
      " 0   water_level  49511 non-null  float64            \n",
      " 1   timestamp    49511 non-null  datetime64[ns, UTC]\n",
      " 2   is_outlier   49511 non-null  bool               \n",
      " 3   x_hat        49511 non-null  float64            \n",
      " 4   result       49511 non-null  float64            \n",
      "dtypes: bool(1), datetime64[ns, UTC](1), float64(3)\n",
      "memory usage: 1.9 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 362.64x224.124 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_pred = prediction_summary_df.sort_values(by=['f1_score'], ascending=False).iloc[0]\n",
    "common_id = best_pred['common_id']\n",
    "model_type = best_pred['model_type']\n",
    "window_size = int(best_pred['window_size']) if best_pred['window_size'] is not None else None\n",
    "center_window = 'cw' if best_pred['center_window'] else 'ncw'\n",
    "normalized = 'normalized' if best_pred['normalized'] else 'regular'\n",
    "threshold = best_pred['threshold']\n",
    "best_pred_df = pd.read_parquet(f'./data/predictions/raw_preprocessed/{normalized}/{common_id}/{window_size}_{center_window}_{model_type}.parquet')\n",
    "best_pred_df.info()\n",
    "# best_pred_df = best_pred_df.loc[best_pred_df['timestamp'] <= '2019-06-01']\n",
    "tex_plots_path = f'../bachelor-thesis/plots/pdfs/{common_id}/'\n",
    "fig, ax = plt.subplots(1, 1, figsize=set_size('thesis'))\n",
    "plt.plot(best_pred_df['timestamp'], best_pred_df['result'], linewidth=0.5,\n",
    "         zorder=-1)\n",
    "plt.scatter(best_pred_df.loc[~best_pred_df['is_outlier'], 'timestamp'],\n",
    "            best_pred_df.loc[~best_pred_df['is_outlier'], 'result'], s=0.1, label='regular (ground truth)')\n",
    "plt.scatter(best_pred_df.loc[best_pred_df['is_outlier'], 'timestamp'],\n",
    "            best_pred_df.loc[best_pred_df['is_outlier'], 'result'], s=0.5, c='C2', label='outliers (ground truth)')\n",
    "\n",
    "plt.suptitle(f'Result of {model_type} based outlier detection of {stations_dict[common_id][\"water_name\"]} - {stations_dict[common_id][\"station_name\"]}',  y=1.05)\n",
    "plt.title(f'(window size={window_size}, {\"no \" if not best_pred[\"center_window\"] else \"\"} center window, {\"not \" if best_pred[\"normalized\"] else \"\"} normalized , threshold={round(threshold, 2)})')\n",
    "plt.grid(alpha=0.25)\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Result ($|x_t - \\hat{x}_t|$)')\n",
    "plt.axhline(y=threshold, color='C3', linestyle='--', linewidth=0.5, label='threshold')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.32),\n",
    "          fancybox=True, shadow=True)\n",
    "plt.savefig(f'{tex_plots_path}od_result_{model_type}_{common_id}_all.pdf', format='pdf',\n",
    "            bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50569 entries, 0 to 50575\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype              \n",
      "---  ------       --------------  -----              \n",
      " 0   water_level  50569 non-null  float64            \n",
      " 1   timestamp    50569 non-null  datetime64[ns, UTC]\n",
      " 2   is_outlier   50569 non-null  bool               \n",
      " 3   x_hat        50569 non-null  float64            \n",
      " 4   result       50569 non-null  float64            \n",
      "dtypes: bool(1), datetime64[ns, UTC](1), float64(3)\n",
      "memory usage: 2.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 362.64x224.124 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "worst_best_pred = None\n",
    "for common_id in prediction_summaries_dict.keys():\n",
    "    if worst_best_pred is None:\n",
    "        worst_best_pred = prediction_summaries_dict[common_id]['regular'].sort_values(by=['f1_score'], ascending=False).iloc[0]\n",
    "    elif prediction_summaries_dict[common_id]['regular'].sort_values(by=['f1_score'], ascending=True).iloc[0]['f1_score'] >= worst_best_pred['f1_score']:\n",
    "        worst_best_pred = prediction_summaries_dict[common_id]['regular'].sort_values(by=['f1_score'], ascending=False).iloc[0]\n",
    "\n",
    "common_id = worst_best_pred['common_id']\n",
    "model_type = worst_best_pred['model_type']\n",
    "window_size = int(worst_best_pred['window_size']) if worst_best_pred['window_size'] is not None else None\n",
    "center_window = 'cw' if worst_best_pred['center_window'] else 'nocw'\n",
    "normalized = 'normalized' if worst_best_pred['normalized'] else 'regular'\n",
    "threshold = worst_best_pred['threshold']\n",
    "worst_best_df = pd.read_parquet(f'./data/predictions/raw_preprocessed/{normalized}/{common_id}/{window_size}_{center_window}_{model_type}.parquet')\n",
    "worst_best_df.info()\n",
    "# best_pred_df = best_pred_df.loc[best_pred_df['timestamp'] <= '2019-06-01']\n",
    "tex_plots_path = f'../bachelor-thesis/plots/pdfs/{common_id}/'\n",
    "fig, ax = plt.subplots(1, 1, figsize=set_size('thesis'))\n",
    "plt.plot(worst_best_df['timestamp'], worst_best_df['result'], linewidth=0.5,\n",
    "         zorder=-1)\n",
    "plt.scatter(worst_best_df.loc[~worst_best_df['is_outlier'], 'timestamp'],\n",
    "            worst_best_df.loc[~worst_best_df['is_outlier'], 'result'], s=0.1, label='regular (ground truth)')\n",
    "plt.scatter(worst_best_df.loc[worst_best_df['is_outlier'], 'timestamp'],\n",
    "            worst_best_df.loc[worst_best_df['is_outlier'], 'result'], s=0.5, c='C2', label='outliers (ground truth)')\n",
    "\n",
    "plt.suptitle(f'Result of {model_type} based outlier detection of {stations_dict[common_id][\"water_name\"]} - {stations_dict[common_id][\"station_name\"]}',  y=1.05)\n",
    "plt.title(f'(window size={window_size}, {\"no \" if not worst_best_pred[\"center_window\"] else \"\"} center window, {\"not \" if worst_best_pred[\"normalized\"] else \"\"} normalized , threshold={round(threshold, 2)})')\n",
    "plt.grid(alpha=0.25)\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Result ($|x_t - \\hat{x}_t|$)')\n",
    "plt.axhline(y=threshold, color='C3', linestyle='--', linewidth=0.5, label='threshold')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.32),\n",
    "          fancybox=True, shadow=True)\n",
    "plt.savefig(f'{tex_plots_path}od_result_{model_type}_{common_id}_all.pdf', format='pdf',\n",
    "            bbox_inches='tight')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "common_id         2386-ch\nwindow_size           3.0\ncenter_window        True\nmodel_type         median\nnormalized          False\nthreshold        5.966555\nf1_score         0.657895\ntn                  50423\nfp                     44\nfn                     34\ntp                     75\nrecall           0.688073\nprecision        0.630252\nName: 9315, dtype: object"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_best_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "       water_level                 timestamp  is_outlier  x_hat  result\n104           72.0 2016-02-17 14:00:00+00:00        True   81.0     9.0\n8795          92.0 2017-03-13 14:00:00+00:00        True   92.0     0.0\n8796          80.0 2017-03-13 15:00:00+00:00        True   92.0    12.0\n9170          59.0 2017-03-30 16:00:00+00:00        True   59.0     0.0\n9171          51.0 2017-03-30 17:00:00+00:00        True   59.0     8.0\n...            ...                       ...         ...    ...     ...\n46791        103.0 2021-12-08 22:00:00+00:00        True   82.0    21.0\n47785         55.0 2022-01-19 17:00:00+00:00        True   79.0    24.0\n47818         23.0 2022-01-21 02:00:00+00:00        True   83.0    60.0\n48172        142.0 2022-02-04 20:00:00+00:00        True  133.0     9.0\n49410         80.0 2022-03-28 22:00:00+00:00        True   49.0    31.0\n\n[70 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>water_level</th>\n      <th>timestamp</th>\n      <th>is_outlier</th>\n      <th>x_hat</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>104</th>\n      <td>72.0</td>\n      <td>2016-02-17 14:00:00+00:00</td>\n      <td>True</td>\n      <td>81.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>8795</th>\n      <td>92.0</td>\n      <td>2017-03-13 14:00:00+00:00</td>\n      <td>True</td>\n      <td>92.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8796</th>\n      <td>80.0</td>\n      <td>2017-03-13 15:00:00+00:00</td>\n      <td>True</td>\n      <td>92.0</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>9170</th>\n      <td>59.0</td>\n      <td>2017-03-30 16:00:00+00:00</td>\n      <td>True</td>\n      <td>59.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9171</th>\n      <td>51.0</td>\n      <td>2017-03-30 17:00:00+00:00</td>\n      <td>True</td>\n      <td>59.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>46791</th>\n      <td>103.0</td>\n      <td>2021-12-08 22:00:00+00:00</td>\n      <td>True</td>\n      <td>82.0</td>\n      <td>21.0</td>\n    </tr>\n    <tr>\n      <th>47785</th>\n      <td>55.0</td>\n      <td>2022-01-19 17:00:00+00:00</td>\n      <td>True</td>\n      <td>79.0</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>47818</th>\n      <td>23.0</td>\n      <td>2022-01-21 02:00:00+00:00</td>\n      <td>True</td>\n      <td>83.0</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>48172</th>\n      <td>142.0</td>\n      <td>2022-02-04 20:00:00+00:00</td>\n      <td>True</td>\n      <td>133.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>49410</th>\n      <td>80.0</td>\n      <td>2022-03-28 22:00:00+00:00</td>\n      <td>True</td>\n      <td>49.0</td>\n      <td>31.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>70 rows  5 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}